\input{preambulo.tex}
%----------------------------------------------------------------------------------------
%	TÍTULO Y DATOS DEL ALUMNO
%----------------------------------------------------------------------------------------

\title{
	Práctica 3.b \\\vspace{1cm}
	Técnicas de Búsqueda basadas en Trayectorias para el
	Problema del Aprendizaje de Pesos en Características
 \vspace{1cm} \\
	El problema del Aprendizaje de Pesos en Características (APC)	\vspace{1cm} \\
	Algoritmos BMB, ILS, VNS, ES e ILS-ES
	\hspace{1cm} 
 }   

\author{Yeray López Ramírez	}                             

\renewcommand*\contentsname{hola}

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

%----------------------------------------------------------------------------------------
% DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}
\input{portada.tex}

\newpage %inserta un salto de página
\newcommand{\code}[1]{\colorbox{light-gray}{\textcolor{alizarin}{\texttt{#1}}}}
\newcommand{\high}[1]{\colorbox{light-gray}{\textcolor{nyellow}{\texttt{#1}}}}

\tableofcontents % para generar el índice de contenidos

\listoffigures

\listoftables

\newpage

%----------------------------------------------------------------------------------------
%	Cuestión 1
%----------------------------------------------------------------------------------------

\section{Descripción del problema}
El problema del Aprendizaje de Pesos en Características (APC) consiste en encontrar una combinación ponderada de un conjunto de características que maximice la precisión de un clasificador y minimice su complejidad. En este problema, se busca determinar la importancia relativa de cada característica para mejorar la eficiencia computacional y la precisión del modelo. El objetivo es encontrar un vector de pesos que asigne valores más altos a las características más importantes y valores más bajos a las características menos relevantes, y que permita eliminar aquellas características que no aporten información relevante para la tarea de clasificación. \\

En otras palabras, el APC busca determinar qué características son más relevantes para un problema dado y cómo combinarlas de manera óptima para obtener el mejor rendimiento de un modelo. \\

El modelo clasificador utilizado en este problema es el 1-NN, el cual es un método de aprendizaje supervisado que clasifica una instancia basándose en la clase de su vecino más cercano en el conjunto de entrenamiento. Además, se utilizará la técnica de validación leave-one-out para evaluar el desempeño del clasificador. La función objetivo que se busca maximizar será una combinación de medidas de precisión (tasa\_clas) y complejidad del clasificador (tasa\_red), dando como resultado el fitness.\\

Los conjuntos de datos utilizados en este problema son \textbf{diabetes}, \textbf{ozone-320} y \textbf{spectf-heart}. Diabetes es un conjunto de datos médicos que contiene información sobre pacientes con diabetes, como su edad, índice de masa corporal, presión arterial y resultados de pruebas de laboratorio, entre otros. Ozone-320 es un conjunto de datos de calidad del aire que contiene mediciones de ozono y otros contaminantes atmosféricos en diferentes ciudades de Estados Unidos. Spectf-heart es un conjunto de datos médicos que contiene información sobre pacientes que se sometieron a pruebas de diagnóstico por imágenes para enfermedades cardíacas. Todos los datasets tienen 2 etiquetas: negativo/positivo o 1.0/2.0 para indicar la clase del vector de características.  
\newpage

\section{Descripción de la aplicación de los algoritmos}
Los algoritmos utilizados para resolver el problema del Aprendizaje de Pesos en Características (APC) son Metaheurísticas que buscan optimizar una función objetivo que combina la precisión y la complejidad del clasificador 1-NN diseñado utilizando un vector de pesos. En este problema, se busca encontrar el mejor subconjunto de características que permita obtener una alta tasa de clasificación y, al mismo tiempo, reducir la complejidad del modelo. \\

Para aplicar estos algoritmos al problema de APC, se utilizó el esquema de representación basado en un vector de tamaño n con valores en [0, 1] que indican el peso asociado a cada característica. La función objetivo fue definida como la combinación con pesos de la tasa de acierto y la tasa de reducción de características del clasificador 1-NN diseñado empleando el vector de pesos. El objetivo es maximizar esta función, multiplicando la tasa de acierto por 0.8 y la tasa de reducción por 0.2, para dar mayor importancia a la clasificación que a la reducción de características.
\[\text{Fit} = 0.8 \cdot \text{precision} + 0.2 \cdot \text{reduction}\]

La implementación en pseudocódigo de la \textbf{función objetivo}:

\begin{minted}{text}
Input(Conjunto de Entrenamiento "Train", Conjunto de Prueba "Test", Vector de pesos W)
Inicio
    aciertos <- CLASIFICAR(Train, Test, W)
    tasa_clas <- aciertos/tamaño_test
    tasa_red <- PESOS_MENOR_UMBRAL(W, 0.1)
    DEVOLVER(0.8·tasa_clas + 0.2·tasa_red)
Fin
\end{minted}

Donde CLASIFICAR llama al modelo clasificador de vecinos 1-NN. El clasificador 1-NN (del inglés "Nearest Neighbor") es un algoritmo de clasificación que se basa en encontrar el vecino más cercano a un ejemplo de prueba en un conjunto de datos de entrenamiento, y asignarle la etiqueta del vecino como la etiqueta del ejemplo de prueba. En otras palabras, el algoritmo encuentra el ejemplo de entrenamiento más cercano al ejemplo de prueba en términos de \textbf{distancia}, y le asigna la etiqueta del ejemplo de entrenamiento como la etiqueta del ejemplo de prueba. La implementación en pseudocódigo del \textbf{clasificador 1NN} es:

\begin{minted}{c++}
Input(Vector características "A", Conjunto Entrenamiento "T", pesos W)
Inicio
    Inicializar min_distancia(INFINITY) y min_index(-1)
    Para cada vector B en T
        distancia <- DISTANCIA_EUCLIDEA(A,B,W)
        Si distancia es menor que min_distancia
            entonces min_index <- T.indice y min_distancia <- distancia
     DEVOLVER(T.GET_ETIQUETA(min_index))
Fin
\end{minted}

Cuando la función objetivo llama a CLASIFICAR lo que realmente hace es ejecutar el clasificador 1-NN con todo el conjunto de prueba. \\

Tanto el clasificador como el algoritmo de Greedy y la Búsqueda Local requieren del cálculo de la distancia entre los ejemplos. La \textbf{distancia euclidiana} es una medida de distancia comúnmente utilizada en problemas de clasificación y agrupamiento. Esta distancia mide la distancia geométrica entre dos puntos en un espacio n-dimensional. Se calcula como la raíz cuadrada de la suma de las diferencias al cuadrado de cada coordenada:

\[d(p,q) = \sqrt{(e^1_1 - e^1_2)^2 + (e^2_1 - e^2_2)^2 + ... + (e^n_1 - e^n_2)^2} =  \sqrt{\sum_{i=1}^n (e^i_1 - e^i_2)^2}\]

En el contexto del clasificador 1-NN, la distancia euclidiana se utiliza para medir la similitud entre dos ejemplos, uno del conjunto de entrenamiento y otro del conjunto de prueba. La idea es comparar el ejemplo de prueba con cada uno de los ejemplos de entrenamiento, y seleccionar la etiqueta del ejemplo más cercano al de prueba.\\

Los pesos w se usan para ajustar la importancia de cada atributo en el cálculo de la distancia euclidiana. Si un atributo tiene un peso alto, entonces su valor tendrá un mayor impacto en la medida de distancia. Por lo tanto, es importante elegir los pesos adecuados para obtener una buena precisión de clasificación. En algunos casos, ciertos atributos pueden ser irrelevantes o redundantes, y su peso puede establecerse en cero para ignorarlos en el cálculo de la distancia. La implementación en pseudocódigo de la \textbf{distancia euclidiana ponderada}:

\begin{minted}{c++}
Input(Vector características "A", Vector características "B", Vector de pesos "W", Umbral=0.1)
Inicio
    Inicializa distancia(0)
    Para cada i en número de características
        Si el peso wi es menor al umbral
            salta la iteración
        Sino
            entonces dist <- wi + (Ai - Bi)²
      DEVUELVE(RAIZ_CUADRADA(dist))
Fin
\end{minted}

Y por último pero no menos el importante, la función de \textbf{leave one out}. El Leave One Out es un procedimiento para evaluar la capacidad predictiva de un modelo de clasificación utilizando todo el conjunto de datos para el entrenamiento y la validación. El proceso consiste en evaluar el modelo n veces, dejando un ejemplo fuera (leave one out) del conjunto de datos en cada iteración para su uso en la validación. El modelo se entrena con los n-1 ejemplos restantes y se utiliza para predecir el ejemplo que se dejó fuera. La precisión del modelo se mide mediante el número de predicciones correctas sobre el total de ejemplos que se dejaron fuera. La implementación en pseudocódigo del \textbf{LOO}:

\begin{minted}{c++}
Input(Conjunto de datos "C", Indice "i")
Inicio
    Dataset Loo <- C
    ELIMINAR_EJEMPLO(Loo, i)
    DEVOLVER(Loo)
Fin
\end{minted}


\section{Estructuras de datos y algoritmos}
\subsection{Estructura de Datos en C++}
En primer lugar, mencionar que se ha elegido el lenguaje de programación C++. Se han definido principalmente dos Estructuras que forman la base del programa:
\begin{itemize}
	\item Struct Ejemplo: contiene un vector de características y un string de etiqueta. Representa a cada individuo en los conjuntos de datos.
	\item Class Dataset: contiene un vector de Ejemplos y vector de etiquetas. Representa a todo el conjunto de datos, puede ser train o test según la lectura de los datos.
	
	\item Class Poblacion: contiene una matriz de poblacion donde cada fila representa un individuo de la misma, un vector de fitness donde guarda el valor de fitness de cada individuo y varios enteros con las posiciones al peor, segundo peor y mejor fitness.
\end{itemize}

En la lectura se aplicó el método de validación cruzada (cross-folding) para evaluar el rendimiento de los algoritmos de selección de características en el problema de Aprendizaje de Pesos en Características (APC). \\

Este método consiste en dividir el conjunto de datos en $k$ particiones de igual tamaño, donde una de las particiones se utiliza como conjunto de prueba y las $k-1$ particiones restantes se utilizan como conjunto de entrenamiento. Este proceso se repite $k$ veces, de tal manera que cada partición se utiliza exactamente una vez como conjunto de prueba. De esta forma, se obtiene una medida más robusta del rendimiento del algoritmo, ya que se evalúa el rendimiento sobre datos que no han sido utilizados para entrenar el modelo. \\

En nuestro problema se utilizó la validación cruzada con $k=5$, lo que significa que se dividieron los datos en 5 particiones de igual tamaño y se realizaron 5 iteraciones del proceso de entrenamiento y evaluación. Para cada iteración, se utilizó una partición diferente como conjunto de prueba y las demás particiones como conjunto de entrenamiento. Se promedió el rendimiento obtenido en las 5 iteraciones para obtener una medida general del rendimiento de cada algoritmo. \\

Para ayudar a la reproducibilidad y verificación de los algoritmos, se nos ha proporcionado los ficheros de datos ya divididos así que el método de lectura se limita a leerlos y aplicar la validación cruzada. La implementación en pseudocódigo del \textbf{método de lectura}:

\begin{minted}{c++}
Input(Una cadena "nombre", Conjunto de Datos "Train", Conjunto de Datos "Test", Indice de test "k")
Inicio
    Si nombre no es igual a "diabetes", "ozone-320" o "spectf-heart"
        entonces DEVOLVER(error)
    Sino
        inicializa train, test
        Para cada i hasta k
            f <- nombre + i
            Si i == k
                 entonces READ(test, f)
            en otro caso
                 READ(train, f)
     DEVOLVER(sucess)
Fin
\end{minted}

La función READ de cada conjunto de datos se encarga de leer el fichero $f$ e integrarlo en la estructura. Se ignoran todos los comentarios y se leen los datos como una matriz de Ejemplos.\\

\subsection{Algoritmos de Trayectoria}
Un algoritmo basado en trayectorias, también conocido como algoritmo de búsqueda de trayectorias, es un enfoque de resolución de problemas que se centra en encontrar una trayectoria o camino óptimo en un espacio de búsqueda.\\

Este tipo de algoritmo se utiliza principalmente en problemas de optimización, donde se busca encontrar la mejor solución dentro de un conjunto de posibles soluciones. La idea es explorar el espacio de búsqueda de manera iterativa, moviéndose de un estado a otro, evaluando la calidad de cada estado y eligiendo la mejor opción en función de un criterio objetivo.\\

La exploración de la trayectoria se realiza a través de movimientos sucesivos entre estados adyacentes en el espacio de búsqueda. Estos movimientos pueden ser determinados por una heurística específica o una mutación aleatoria de la población que guíe la búsqueda hacia soluciones prometedoras y no atascarse en óptimos locales.\\

Los algoritmos de trayectoria se diferencian de otros enfoques de optimización en que no exploran exhaustivamente todo el espacio de búsqueda, sino que se centran en una trayectoria particular que conduce a una solución óptima. Esto permite reducir el tiempo de búsqueda y encontrar soluciones aceptables en problemas complejos con grandes espacios de búsqueda.\\

Algunos ejemplos de algoritmos basados en trayectorias incluyen la búsqueda local (Búsqueda Local Reiterada, ILS), la búsqueda multiarranque básico (BMB), Búsqueda de vecindad variable (VNS),  el enfriamiento simulado (ES) y su versión iterativa (ILS-ES). Estos algoritmos tienen diferentes estrategias de búsqueda y características específicas que los hacen adecuados para diferentes tipos de problemas y requisitos de optimización.

\subsubsection{Búsqueda Local}
En el algoritmo de \textbf{búsqueda local} la solución inicial se generó de forma aleatoria utilizando una distribución uniforme en [0, 1], y el movimiento de cambio por mutación normal Mov(W,s) se utilizó como esquema de generación de vecinos en la Búsqueda Local. En cada iteración de la Búsqueda Local, se mutó una componente i del vector de pesos en un orden aleatorio distinto para cada solución, hasta que se alcanzó una solución mejor o se modificaron todas las posiciones una vez sin conseguir una mejora. Se implementa de la siguiente forma:
\begin{minted}{text}
Input(Conjunto de datos "Train")
Inicio
GENERAR_SOLUCION_INICIAL(Wact, Train.NUMERO_CARACTERÍSTICAS)
objetivoActual <- FUN_OBJETIVO(Train, Wact)
Inicializar iteraciones, iter_vecinos = 0, W = Wact
Mientras que iter_vecinos < 20*Sact.SIZE y iteraciones menor que 15,000
Vec_indices <- GENERAR_VECINDARIO(W.SIZE)
Inicializar bool mejora <- false
Para cada i en Vec_indices y mientras no haya mejora
GENERAR_VECINO(W, i, 0.8)
objetivo <- FUN_OBJETIVO(Train, W)
Si el objetivo es mayor que el actual
Inicializar iter_vecinos = 0
objetivoActual <- objetivo
Wact = W
mejora = true
iter_vecinos+1
iter+1

DEVOLVER(Wact)
\end{minted}
A continuación se describe con detalle los esquemas:
\begin{itemize}
	\item Generación de la solución inicial: usamos la librería \code{random.hpp} proporcionada, concretamente Random::get<std::vector>(0.0, 1.0, numCaracteristicas) que genera un vector aleatorio de números reales entre 0 y 1 de tamaño numCaracterísticas.
	\item Generación de vecindario: usamos la librería \code{random.hpp} para hacer un shuffle a los índices de pesos.
	\item Generación de vecinos: esta vez hay que tener más cuidado pues hay que sumar un vector Z con distribución normal y respetar la representación de los pesos [0,1]. Una implementación sencilla en pseudocódigo es la siguiente:
	\begin{minted}{c++}
Input(Pesos "W", indice "i", valor de "media" = 0, valor de" varianza" = 0.8)
Inicio
z <- DISTRIBUCION_NORMAL(0, SQRT(varianza))
Si Wi + z es mayor a 1
TRUNCAR(Wi, 1)
Si Wi + z es menor a 0
TRUNCAR(Wi, 0)
Si no
Wi <- Wi + z
DEVOLVER(W)
	\end{minted}
	
	\item Criterio de aceptación: se cumple cuando el objetivo del vecino generado es mayor que el actual, lo controlamos con el valor de mejora.
\end{itemize}

\subsection{Algoritmo de Búsqueda Multiarranque Básica}
La búsqueda multiarranque básica es un enfoque utilizado en problemas de optimización que busca mejorar la calidad de las soluciones encontradas mediante la exploración de múltiples arranques o puntos iniciales.\\

En lugar de comenzar la búsqueda desde un único punto inicial, la búsqueda multiarranque básica realiza múltiples arranques desde diferentes puntos iniciales de manera aleatoria. Cada arranque se considera como una ejecución independiente del algoritmo de búsqueda, lo que permite explorar diferentes regiones del espacio de búsqueda y evitar quedar atrapado en óptimos locales.\\

El proceso de búsqueda multiarranque básica se puede describir en los siguientes pasos:

\begin{enumerate}
\item \textbf{Generación de pesos iniciales:} Se generan múltiples pesos iniciales de manera aleatoria.

\item \textbf{Aplicación del algoritmo de búsqueda:} Para cada punto inicial, se ejecuta un algoritmo de búsqueda (en nuestro caso, búsqueda local) para encontrar una solución localmente óptima o mejorar la solución actual.

\item \textbf{Evaluación y selección de la mejor solución:} Se evalúan las soluciones encontradas en cada arranque y se selecciona la mejor solución obtenida como resultado final.

\item \textbf{Criterio de parada: } Se establece un criterio de parada para determinar cuándo finalizar el proceso de búsqueda, como un número máximo de iteraciones o un límite de tiempo. En nuestro caso se establece un máximo de 15000 iteraciones totales (1000 en cada ejecución de búsqueda local). El pseudocódigo sería:


\end{enumerate}

La búsqueda multiarranque básica es especialmente útil cuando el espacio de búsqueda es complejo y existen múltiples óptimos locales. Al explorar diferentes puntos iniciales, existe una mayor probabilidad de encontrar soluciones de mayor calidad y evitar quedar atrapado en óptimos locales subóptimos.

\begin{algorithm}[H]
	\SetKwFunction{BMB}{BMB}
	\SetKwInOut{Input}{Entrada}
	\SetKwInOut{Output}{Salida}
	
	\Input{Dataset entrenamiento, vector Sact, iter, maxiter}
	\Output{mejorObjetivo}
	
	\BlankLine
	\BMB{Dataset train, vector Sact, iter, maxiter}:
	\BlankLine
	i = 0	
	\BlankLine
	\While{i \ < \ iter}{
		% Generar aleatoria
		Sact = generarVectorAleatorio(0,1)
		
		% Evaluar BL
		objetivo = busquedaLocal(train, Sact, maxiter/iter)\;
		
		% Guardar si es mejor
		\If{objetivo \ > \ mejorObjetivo}{
			mejorS = Sact\;
			mejorObjetivo = objetivo\;
		}
		
		i++\;
	}
	
	\Return{mejorObjetivo}\;
\end{algorithm}

\subsection{Búsqueda Local Iterativa}
La búsqueda local iterativa es una estrategia de optimización que se utiliza para mejorar una solución inicial mediante iteraciones locales. Consiste en realizar modificaciones locales en la solución actual y evaluar si estas modificaciones conducen a una mejora en la función objetivo.\\

En la búsqueda local iterativa, se parte de una solución inicial y se aplica un operador de vecindad que genera soluciones vecinas mediante pequeñas modificaciones en la solución actual. Luego, se evalúa cada solución vecina generada y se selecciona la mejor solución como la nueva solución actual. Este proceso se repite en iteraciones sucesivas, utilizando siempre la mejor solución encontrada hasta el momento.\\

La diferencia principal entre la BMB y la ILS radica en la generación de soluciones iniciales. Mientras que en la búsqueda local iterativa se parte de una única solución inicial y se realiza la mejora iterativa, en la búsqueda multiarranque básica se generan múltiples soluciones iniciales de forma aleatoria y se aplican búsquedas locales independientes a cada una de ellas. Esto permite explorar diferentes regiones del espacio de búsqueda y aumentar las posibilidades de encontrar una solución de mayor calidad global, al escapar de posibles óptimos locales y abordar diferentes configuraciones iniciales.\\

\begin{algorithm}[H]
	\SetKwFunction{ILS}{ILS}
	\SetKwInOut{Input}{Entrada}
	\SetKwInOut{Output}{Salida}
	
	\Input{Dataset train, solución inicial Sact, iteraciones iter, máximas iteraciones maxiter}
	\Output{Mejor objetivo encontrado}
	
	\BlankLine
	\ILS{Dataset train, solución inicial Sact, iteraciones iter, máximas iteraciones maxiter}:
	\BlankLine	
	
	\tcp{Al menos 2 mutaciones}
	mutaciones = 0.10 * numCaracterísticas\\
	\If{mutaciones < \ 2}{
		mutaciones = 2
	}
	
	generaSolucionInicial(S, numCaracteristicas)
	
	objetivo = busquedaLocal(entrenamiento, S, iter, maxiter)
	\BlankLine
	mejorS = S\\
	mejorObjetivo = objetivo\\
	\While{i \ < \ iter}{
		\For{ j = 0; j < mutaciones; j++}{
			S = mutacion(Sact, Random(0, n), $\sigma$)\;
		}
		objetivo = busquedaLocal(train, S, maxiter/iter)\;
		
		\If{objetivo \ > \ mejorObjetivo}{
			mejorObjetivo = objetivo\;
			mejorS = S\;
		}
		i++\;
		iter = 0\;
	}
	
	\Return{mejorObjetivo}\;
\end{algorithm}

\subsection{Algoritmo de Búsqueda de Vecindad Variable}
Variable Neighborhood Search (VNS) es un algoritmo de búsqueda local que combina la exploración de múltiples vecindarios en busca de soluciones óptimas. La idea principal detrás de VNS es explorar diferentes estructuras vecinas de una solución actual para superar los óptimos locales y encontrar soluciones de mejor calidad.\\

El algoritmo VNS se compone de los siguientes pasos:\\
\begin{algorithm}[H]
	\SetKwFunction{VNS}{VNS}
	\SetKwInOut{Input}{Entrada}
	\SetKwInOut{Output}{Salida}
	
	\Input{Dataset train, solución inicial Sact, iteraciones iter, máximas iteraciones maxiter, atributos k}
	\Output{Mejor objetivo encontrado}
	
	\BlankLine
	\VNS{Dataset train, solución inicial Sact, iteraciones iter, máximas iteraciones maxiter, atributos k}:
	\BlankLine	
	
	\tcp{Al menos 2 mutaciones}
	mutaciones = 0.10 * numCaracterísticas\\
	\If{mutaciones < \ 2}{
		mutaciones = 2
	}
	
	generaSolucionInicial(S, numCaracteristicas)
	
	objetivo = busquedaLocal(entrenamiento, S, iter, maxiter)
	\BlankLine
	mejorS = S\\
	mejorObjetivo = objetivo\\
	\While{i \ < \ iter}{
		\For{ j = 0; j < mutaciones; j++}{
			S = mutacion(Sact, Random(0, n), $\sigma$, k)\;
		}
		objetivo = busquedaLocal(train, S, maxiter/iter, k)\;
		
		\If{objetivo \ > \ mejorObjetivo}{
			mejorObjetivo = objetivo\;
			mejorS = S\;
			k=1
		}
		\If{k $\leq$ KMAX}{
			k++;
		}
		\Else{
			k = 1;
		}
		
		i++\;
		iter = 0\;
	}
	
	\Return{mejorS}\;
\end{algorithm}

\begin{enumerate}
\item Seleccionar una solución inicial aleatoria.
\item Definir un conjunto de vecindarios o estructuras de vecindad. Cada vecindario representa un conjunto de soluciones cercanas a la solución actual.
\item Iterar hasta que se cumpla un criterio de parada:
\begin{enumerate}
	\item Seleccionar un vecindario aleatoriamente.
	\item  Aplicar una búsqueda local en el vecindario seleccionado para mejorar la solución actual.
	\item  Si se encuentra una solución mejor, actualizar la solución actual.
	\item  Si no se encuentra una solución mejor, cambiar al siguiente vecindario en el conjunto de vecindarios.
\end{enumerate}

\item Repetir el paso 3 hasta alcanzar el criterio de parada.
\end{enumerate}
La principal diferencia entre VNS y otros algoritmos de búsqueda local es la exploración de múltiples vecindarios. Al cambiar entre diferentes vecindarios, VNS puede evitar quedar atrapado en óptimos locales al explorar nuevas estructuras vecinas. Esto permite una mayor capacidad de exploración y una mayor probabilidad de encontrar soluciones de mejor calidad.\\

\subsection{Algoritmo de Enfriamiento Simulado}

\subsection{Algoritmo de Búsqueda Local Iterativa - con ESs}


\subsection{Algoritmos Meméticos}
Un algoritmo memético es una variante del algoritmo genético que combina principios de la evolución biológica con el aprendizaje cultural. Este enfoque híbrido busca aprovechar la capacidad de los algoritmos genéticos para explorar y explotar el espacio de búsqueda, al mismo tiempo que incorpora mecanismos de mejora basados en el conocimiento adquirido a lo largo de las generaciones. \\

En un algoritmo memético, además de los componentes tradicionales de un algoritmo genético, se incorpora un proceso de aprendizaje o mejora local llamado operador memético. Este operador se aplica a los individuos seleccionados de la población para refinar aún más sus soluciones y aumentar su calidad.\\

El operador memético que vamos a utilizar es la Búsqueda Local Primer Mejor.\\

La idea principal detrás de los algoritmos meméticos es que la mejora local puede llevar a soluciones más óptimas y acelerar la convergencia del algoritmo, especialmente cuando se tienen regiones prometedoras en el espacio de búsqueda. Los operadores meméticos ayudan a explotar estas regiones y pueden adaptarse según las características específicas del problema.

En resumen, un algoritmo memético combina la exploración global y la explotación local al integrar una búsqueda local en un algoritmo genético. 


\subsubsection{Algoritmo Memético Mejores (AM-Best)}
El Algoritmo Memético Mejor(AMM-Best) es un método por el cual se aplica el algoritmo genético generacional convencional y se aplica búsqueda local al 10\% mejor de la población cada cierto número de iteraciones.\\

Para conseguirlo el método utilizado ha sido el de ordenar un vector de fitness de mayor a menor y extraido el primer 10\% del vector.\\

En un AM-Best la nueva generación reemplaza por completo a la generación anterior ya que es un AGG modificado. Esto implica que solo los individuos de la nueva generación participarán en la siguiente iteración del algoritmo. A medida que avanza el algoritmo, la calidad promedio de los individuos en cada generación puede mejorar, ya que los mejores individuos tienen más probabilidades de ser seleccionados y transmitir sus características a las generaciones futuras.\\

Su implementación en pseudocódigo sería:

\begin{algorithm}[H]
	\SetKwFunction{AMAll}{AM-All}
	\SetKwInOut{Input}{Entrada}
	\SetKwInOut{Output}{Salida}
	
	\Input{Dataset entrenamiento, maximo Iters, pmut, pcruce}
	\Output{mejor individuo}
	
	\BlankLine
	\AMAll{Dataset entrenamiento, maximo Iters, pmut, pcruce}:
	\BlankLine
	Poblacion pop = generar poblacion aleatoria;\\
	funcionObjetivo(train);\\
	iter++;\\
	
	\While{iter < maximoIters}{
		\For{i=0 to tamanio de poblacion}{
			nueva poblacion = torneoBinario(poblacion)
		}
		
		\For{i=0 to tamanio poblacion * pcross}{
			padre1 = poblacion nueva[i];\\
			padre2 = poblacion nueva[i+1];\\
			\BlankLine
			hijo1,hijo2 = operadorBLX(padre1, padre2);
			\BlankLine
			poblacion nueva[i] = hijo1;\\
			poblacion nueva[i+1]=hijo2;\\
		}
		
		aplicarMutacion(poblacion nueva, pmut)\\
		
		fitness = funcionObjetivo(train);\\
		iter++;\\
		elitismoDos(poblacion, poblacion nueva);\\
		
		poblacion = nueva poblacion; \\
		
		maxBL = 2* numero de carecteristicas; \\
		\If{generacion \%10 == 0}{
			mejores = obtener (tamanio poblacion *pmut) individuos con mejor fitness
			\For{i=0 to tamanio mejores and iter < maxIters}{
				fitness = busquedaLocal(train, mejores[i], it, maxBL);\\
				iter += it;
			}
		}
	}
	\Return{mejor individuo}
\end{algorithm}

\newpage

\section{Procedimiento de desarrollo}
Se ha desarrollado la práctica en C++ usando VScode.  Se usa el random.hpp y el CMakeLists.txt de prácticas, los pseudocódigos de teoría y prácticas. Lo que falta se toma de Internet, la mayoría de Stackoverflow \cite{Stackoverflow}, geekforgeeks \cite{greekforgeeks} y chatgpt \cite{chatgpt}. \\

El procedimiento de desarrollo ha sido:
\begin{itemize}
	\item Lectura y búsqueda de información tanto en el material de teoría y prácticas como de Internet. En la figura \ref{fig:mi_imagen} se puede ver el resumen:
	\begin{figure}[h]
		\centering
		\includegraphics[width=\textwidth]{resumen.png}
		\caption{Estudio del problema}
		\label{fig:mi_imagen}
	\end{figure}

	\item Una vez se tiene claros los conceptos, creamos un nuevo directorio practicas1 con el material de prácticas. Creamos los directorios src, headers y reusamos el CMakeLists.txt y el random.hpp de tools.zip. Creamos un fichero .cpp y .h por algoritmo (esto cambiará) y el main.cpp. Los metemos en sus respectivos directorios y abrimos VScode.
	
	\item Primero vamos a definir una estructura de datos que será la base de todo el funcionamiento. En mi caso se abstraen los ejemplos en un Struct y se usa una clase Dataset para integrar vectores de ejemplos. Hardcodeamos una matriz de ejemplo y probamos hasta que funcione.
	
	\item Con la estructura montada pasamos a leer los datos. Para ello he recurrido a una practica de Estructura de Datos donde leía matrices de ficheros y la modifiqué para ignorar los comentarios y adaptarla al dataset.
	También he recurrido a Stackoverflow y chatgpt para las dudas. De paso configuramos el CMakeLists.txt con los ficheros de src y headers. IMPORTANTE: añadir optimización al compilador con el parámetro -02, será clave para la búsqueda local después.
	
	\item Llegados a este punto ya podemos empezar a implementar los métodos. Se implementarán en orden de dificultad y dependencia:
	\begin{enumerate}
		\item Algoritmo 1NN
		\item Algoritmo Greedy RELIEF
		\item Algoritmo Búsqueda Local Primer Mejor
		\item Algoritmo Genéticos: generacional y luego estacionario
		\item Algoritmos Meméticos: all, random y por último AM-best.
	\end{enumerate}
	Para verificar el correcto funcionamiento del algoritmo 1NN y la lectura de datos se ha recurrido a la  \href{https://mh2223.danimolina.net/testsol.html}{web de la asignatura} y junto a la ayuda de geeksforgeeks.org\cite{greekforgeeks}, una página muy recomendada para implementación de multitud algoritmos y problemas, se puede implementar el 1-NN sencillamente. 
	
	\item Una vez tenemos el clasificador pasamos a la implementación de Greedy y la BL. El pseudocódigo proporcionado de Greedy junto a la explicación del mismo en prácticas es suficiente para implementarlo aunque he consultado en la Universidad de Radboud \cite{runl} una tesis sobre la aplicación de algoritmos RELIEF en bioinformática. En cambio para la búsqueda Local, el pseudocódigo de teoría es insuficiente por lo que he recurrido nuevamente a Internet. Encontré un documento de la Universidad de la Laguna sobre sistemas Inteligentes \cite{ull}. En la página 43 encontramos un pseudocódigo más completo y del que nos basaremos para implementarlo. Para modular el código se ha utilizado los esquemas dados en el guión de prácticas.
	
	\item Para la implementación de los algoritmos genéticos podemos usar el repositorio de innovaMH \cite{innovaMH} proporcionado por Daniel Molina. Levantando docker localmente y observando la parte2.jl se entiende perfectamente y con gran detalle como implementar los algoritmos genéticos. 
	
	\item Para la implementación de los algoritmos meméticos he recurrido al seminario y guión que junto a los algoritmos genéticos ya implementados podemos completarlos sin dificultad.
\end{itemize}

\section{Experimentos}
El formato de ejecución de la práctica es:\\
\code{./practica1 <Algoritmo>  \  <Semilla(\textit{opcional})>}\\

Para los algoritmos GENÉTICOS se le añade como parámetro el operador:\\
\code{./practica1 <Algoritmo>  \  <Operador(\textit{BLX por defecto})> \ <Semilla(\textit{opcional})>}\\

Donde:
\begin{itemize}
	\item \code{<Algoritmo>} puede ser: 'sin parametro/vacio', 'oneNN', 'Greedy', 'BL', 'AGG', 'AGE', 'AM-All', 'AM-Rand', 'AM-Best'.
	
	\item \code{<Operador>} puede ser: 'sin parametro/vacio', 'Aritmetrico', 'BLX'.
	\item \code{<Semilla>} puede ser cualquier número.
\end{itemize}

Por ejemplo:
\begin{itemize}
	\item \code{./practica1 }: ejecutará la práctica con el clasificador 1-NN.
	\item \code{./practica1 AM-Rand}: ejecutará la práctica con el clasificador 1-NN mejorado con el Algoritmo Memético Aleatorio, operador BLX y semilla aleatoria.
	\item \code{./practica1 AGG Aritmetrico}: ejecutará la práctica con el clasificador 1-NN mejorado con el Algoritmo Genético Generacional, operador Aritmetrico y semilla aleatoria.
	\item \code{./practica1 AGE BLX 1}: ejecutará la práctica con el clasificador 1-NN mejorado con el Algoritmo Genético Estacionario, operador BLX y semilla 1.
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{greedy.png}
	\caption{Ejecución de Greedy}
	\label{fig:greedy}
\end{figure}
Nota: Se añade la tasa\_clas de entrenamiento para comparar en la web. Se puede desactivar quitando el parámetro \code{true} en la linea 142 en main.cpp. Para la ejecución de las tablas siguientes se ha desactivado para mejorar los tiempos. \\

\subsection{Resultados algoritmos de búsqueda}
Las tablas que se presentan a continuación corresponden a resultados obtenidos por tres algoritmos (1NN, greedy y BL) aplicados al problema del Aprendizaje de Pesos en Características (APC) en tres conjuntos de datos diferentes (Diabetes, Ozone y Spectf-heart). Cada tabla muestra los porcentajes de clasificación, reducción del número de características, fitness y tiempo de ejecución para cada partición del conjunto de datos. Se busca comparar la eficacia de ambos algoritmos en términos de calidad de la solución y tiempo de ejecución.

\input{tabla1nn.tex}

En la tabla \ref{tab:1nn} se puede observar que los resultados de clasificación son bastante buenos con un porcentaje de clasificación correcta de hasta el 85\% en spectf-heart. El porcentaje de reducción en el número de características es del 0\% ya que no se aplica ninguna selección de características.\\

Los valores de fitness oscilan entre 54,69 y 68,31, lo que indica que el algoritmo no ha encontrado necesariamente las soluciones óptimas para todos los conjuntos de datos. Por último, los tiempos de ejecución son bastante bajos, con valores inferiores a 0,01 segundos para todos los conjuntos de datos y particiones.

\input{tablagreedy.tex}

En la tabla \ref{tab:Greedy} se observa que la media de los fitness obtenidos para cada conjunto de datos varía entre 55.17 y 68.07, lo que indica que el algoritmo es capaz de encontrar soluciones de igual calidad que el 1NN.\\

La diferencia está en que el \% de reducción en el número de características seleccionadas varía entre 0\% y 12.5\%, lo que significa que el algoritmo no siempre es capaz de reducir significativamente el número de características sin comprometer el rendimiento del modelo. Esto se debe a que Greedy maximiza la tasa\_clas, no el fitness al completo por lo que no tiende a reducir. Al igual que el 1NN, los tiempos son rápidos.

\input{tablaBL.tex}
Al analizar los resultados de la tabla \ref{tab:bl}, se observa que el algoritmo BL obtiene mejores resultados que el algoritmo Greedy y 1-NN en términos de fitness para todas las particiones y conjuntos de datos. Además, el porcentaje de reducción es significativamente mayor en promedio para el algoritmo BL, lo que sugiere que el número de características seleccionadas es menor en comparación con el algoritmo Greedy.\\

Sin embargo, podemos observar el alto coste computacional que supone ejecutar la búsqueda. Los tiempos multiplican por cientos al de Greedy y 1NN.

\input{tablaFinal.tex}

En la tabla \ref{tab:final} se presentan los resultados globales para los tres algoritmos en los tres conjuntos de datos. En general, el \textbf{algoritmo BL} tuvo un mejor rendimiento en términos de porcentaje de reducción y agregación, aunque tuvo una reducción de dimensiones más alta. El algoritmo 1-NN es el mejor en términos de porcentaje de clasificación, pero no es capaz de reducir la dimensionalidad del conjunto de datos. Por otro lado, el algoritmo RELIEF tuvo un desempeño inferior en comparación con BL, aunque logró reducir algo la dimensionalidad del conjunto de datos.\\

En cuanto a los conjuntos de datos individuales, en Diabetes, los tres algoritmos lograron un rendimiento similar en términos de porcentaje de clasificación y agregación, aunque BL tuvo la reducción de dimensionalidad más alta. En Ozone, BL tuvo un mejor rendimiento que 1-NN y RELIEF en términos de porcentaje de clasificación y agregación, pero también tuvo una reducción de dimensionalidad más alta. En Spectf-heart, BL también tuvo un mejor rendimiento en comparación con 1-NN y RELIEF, aunque tuvo una reducción de dimensionalidad más alta.\\

\subsection{Resultados Algoritmos Genéticos y Meméticos}

\input{tablaAGG-CA.tex}
En la tabla \ref{tab:AGG_CA} se puede observar que los resultados de clasificación son bastante buenos con un porcentaje de clasificación correcta de hasta el 85\% en spectf-heart. El porcentaje de reducción en el número de características es del 45\% aproximadamente aunque en diabetes reduce mucho mientras que el resto se queda en 30\%.\\

Los valores de fitness oscilan entre 63,52 y 74,62, lo que indica que el algoritmo no ha encontrado necesariamente las soluciones óptimas para todos los conjuntos de datos. Por último, los tiempos de ejecución son considerablemente altos en comparación a los algoritmos previos, de unos 50 segundos por partición.

\input{tablaAGG-BLX.tex}
En la tabla \ref{tab:AGG_BLX} se puede observar que los resultados de clasificación han bajado respecto antes pero ha aumentado la reducción sensiblemente. El porcentaje de reducción en el número de características es del 50\% aproximadamente aunque en diabetes reduce mucho mientras que el resto se queda en 40\%.\\

Los valores de fitness oscilan entre 63,62 y 74,23, lo que indica que el operador de cruce no ha mejorado prácticamente EN MI CASO aunque debería ser algo mejor que el Aritmétrico aleatorio. Por último, los tiempos de ejecución son similares al anterior.

\input{tablaAGE-CA.tex}
En la tabla \ref{tab:AGE_CA} se puede observar que los resultados de clasificación vuelven a ser altos como en el AGG, de un 84,51\% el que más. El porcentaje de reducción en el número de características es menor, de un 20\% para ozone y heart aunque en diabetes reduce un 60\%. Considero que los porcentajes de reducción son algo más bajos de lo que esperaba realmente pues debería reducir igual o más que el AGG.

Los valores de fitness oscilan entre 66,80 y 72,06, lo que indica que el algoritmo AGE no ha mejorado EN MI CASO aunque debería ser algo mejor que el AGG debido a la reducción. Por último, los tiempos de ejecución son sensiblemente más altos aunque aún asumibles de ejecutar.

\input{tablaAGE-BLX.tex}
En la tabla \ref{tab:AGE_BLX} se puede observar que los resultados de clasificación vuelven a ser altos, de un 83,95\% el que más. El porcentaje de reducción en el número de características es menor, de un 20\% para ozone aunque en diabetes reduce un 65\%. Igual que con AGG, considero que el operador BLX no mejora EN MI CASO pero debería ser igual o mejor que el CA.

Los valores de fitness oscilan entre 65,81 y 72,98, lo que indica que el algoritmo AGE no ha mejorado EN MI CASO aunque debería ser algo mejor que el AGG debido a la reducción. Por último, los tiempos de ejecución son razonables, menos de un minuto.

\input{tablaAM-All.tex}
En la tabla \ref{tab:AM_ALL} se puede observar que los resultados de clasificación vuelven a ser altos, de un 83,94\% el que más. Esta vez el porcentaje de reducción es condirable para diabetes y heart aunque ozone se resiste.

Los valores de fitness oscilan entre 66,64 y 79,15, lo que indica que el algoritmo AM ha mejorado respecto a todos los anteriores lo cual es lógico ya que afina los pesos mediante la búsqueda local. Por último, los tiempos de ejecución son de los más bajos de todos, unos 47 segundos.

\input{tablaAM-Rand.tex}
En la tabla \ref{tab:AM_RAND} se puede observar que los resultados de clasificación y reducción se muy similares al memético con todo. Mejora el fitness en Ozone y heart pero lo empeora en Diabetes. Por último, los tiempos de ejecución son razonables, dentro del minuto por partición.

\input{tablaAM-Best.tex}
En la tabla \ref{tab:AM_BEST} se puede observar que las mejores tasas de clasificación y reducción de todos los algoritmos vistos hasta ahora. Se llega a alcanzar una tasa de clasificación del 86,53\% y una de reducción del 64,55\% con un fitness máximo de 82,13.

\input{tablaFinal2.tex}
 A continuación, se presenta un análisis exhaustivo considerando las tasas de clasificación y reducción, así como el fitness y tiempo de ejecución:\\
 
 La tasa Agr. es un factor crucial en el análisis de los algoritmos, ya que representa el fitness o medida de calidad del desempeño de los mismos. Un alto valor de tasa Agr. indica que el algoritmo ha logrado un buen equilibrio entre la precisión de clasificación y la reducción de características, lo cual es deseable en problemas de clasificación. Al analizar las tasas Agr. en los diferentes conjuntos de datos y algoritmos, podemos observar lo siguiente:
 
 \begin{itemize}
 	\item Conjunto de datos Diabetes: Los algoritmos AGG-CA y AM-(10,0.1m) obtienen las tasas Agr. más altas en este conjunto de datos. Esto indica que logran un rendimiento sobresaliente al considerar tanto la precisión de clasificación como la reducción de características. Los algoritmos AGG-BLX, AGE-BLX y AGE-CA también muestran tasas Agr. competitivas.
 	
 	\item Conjunto de datos Ozone: Nuevamente, los algoritmos AGG-CA y AM-(10,0.1m) destacan al obtener las tasas Agr. más altas en este conjunto de datos. Esto sugiere que estos algoritmos logran un buen equilibrio entre precisión y reducción de características. Los algoritmos AGG-BLX, AGE-BLX y AGE-CA también obtienen tasas Agr. significativas.
 	
 	\item Conjunto de datos Spectf-heart: En este conjunto de datos, el algoritmo AM-(10,1.0) se destaca al lograr la tasa Agr. más alta. Esto implica que el algoritmos ha obtenido un buen desempeño tanto en la precisión de clasificación como en la reducción de características. Los algoritmos AGG-CA, AGG-BLX, AGE-BLX y AGE-CA también exhiben tasas Agr. notables en este conjunto de datos.
 \end{itemize}

Tasa de clasificación: La tasa de clasificación indica qué tan bien los algoritmos predicen correctamente las etiquetas de clase en los conjuntos de datos. Se puede observar que los algoritmos AGG-CA y AM-(10,0.1m) obtienen las tasas de clasificación más altas en la mayoría de los conjuntos de datos, siendo especialmente buenos en el conjunto Spectf-heart. Estos algoritmos superan al clasificador 1NN, que se considera como referencia (basado en el algoritmo de clasificación one nearest neighbor). Sin embargo, se observa que algunos algoritmos, como BL y AGE-CA, también logran tasas de clasificación competitivas en ciertos conjuntos de datos.\\

Tasa de reducción: La tasa de reducción muestra qué tan bien los algoritmos pueden reducir la dimensionalidad de los conjuntos de datos, eliminando características irrelevantes o redundantes. Los algoritmos AM-(10,0.1) y AM-(10,0.1m) obtienen las tasas de reducción más altas en general, lo que indica que son efectivos para reducir la dimensionalidad de los conjuntos de datos. Esto significa que pueden seleccionar características relevantes y eliminar características redundantes, lo que puede mejorar el desempeño general del clasificador.\\

Tiempo de ejecución: El tiempo de ejecución es otro factor a considerar, ya que indica la eficiencia computacional de los algoritmos. Los algoritmos basados en algoritmos genéticos (AGG-BLX, AGG-CA, AGE-BLX y AGE-CA) generalmente requieren más tiempo de ejecución en comparación con otros algoritmos, debido a la naturaleza iterativa y la manipulación de poblaciones. Por otro lado, los algoritmos basados en algoritmos meméticos (AM-(10,1.0), AM-(10,0.1) y AM-(10,0.1m)) también pueden requerir un tiempo de ejecución considerable debido a la aplicación de la búsqueda local en toda la población o en una parte de ella. Los algoritmos BL y RELIEF, que se basan en la búsqueda local, también pueden tener un tiempo de ejecución significativo dependiendo del tamaño de la población.\\

En resumen, los resultados muestran que los algoritmos AGG-CA y AM-(10,0.1m) logran altas tasas de clasificación en general, mientras que los algoritmos AM-(10,0.1) y AM-(10,0.1m) obtienen altas tasas de reducción. Sin embargo, es importante tener en cuenta el tiempo de ejecución, ya que los algoritmos basados en algoritmos genéticos y meméticos suelen requerir más tiempo para converger. Dependiendo de las necesidades del problema y los recursos disponibles, se puede seleccionar el algoritmo que mejor se ajuste a los requisitos de rendimiento y tiempo de ejecución.

\bibliography{citas} %archivo citas.bib que contiene las entradas 
\bibliographystyle{plain} % hay varias formas de citar

\end{document}
