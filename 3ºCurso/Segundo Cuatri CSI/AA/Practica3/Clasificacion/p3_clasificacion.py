# -*- coding: utf-8 -*-
"""P3_clasificacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b6ReElHVWsobN1MzIjTFSQ7qkWG1o71O

# Aprendizaje Automático - Práctica 3 - Ajuste de Modelos Lineales

# Problema de Clasificación

#### Valoración máxima: 6 puntos

#### Fecha límite de entrega: 4 de Junio de 2023 a las 23:59

#### Entrega a través de https://pradogrado2223.ugr.es/

### Nombre completo: <mark>Yeray López Ramírez</mark>



---
"""

import numpy as np  # Vectores
import pandas as pd  # Dataframes
from matplotlib import pyplot as plt  # Gráficas
import seaborn as sns  # Gráficas más completas
from IPython.display import display, Latex, Markdown  # Tablas

# Funciones SKLEARN

from sklearn.model_selection import cross_val_predict # Validacion cruzada

# Modelos
from sklearn.decomposition import PCA # PCA
from sklearn.svm import OneClassSVM # Support Vector Machine
from sklearn.linear_model import LogisticRegression # Logistic Regression

from sklearn.model_selection import train_test_split  # División de datos

# Normalización
from sklearn.preprocessing import StandardScaler  # Media 0 y desviación estándar 1

# Métricas
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score  # Exactitud
from sklearn.metrics import confusion_matrix  # Matriz de confusión
from sklearn.metrics import precision_score  # Precisión
from sklearn.metrics import recall_score  # Exhaustividad o sensibilidad
from sklearn.metrics import f1_score  # Valor F1

from sklearn.feature_selection import VarianceThreshold # Varianza
from sklearn.model_selection import learning_curve  # Curva de Aprendizaje

# Fijar semilla
np.random.seed(1)

#Tamaño de fuente para las gráficas
SMALL_SIZE = 8
MEDIUM_SIZE = 10
BIGGER_SIZE = 12
TITLE_SIZE = 16

plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes
plt.rc('axes', titlesize=TITLE_SIZE)     # fontsize of the axes title
plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels
plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels
plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels
plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize

"""**Normas de desarrollo y entrega de trabajos**

- Única y exclusivamente se debe entregar este Notebook de Colab (fichero .ipynb). No es necesario entregar ninguna memoria externa, pero el código debe estar bien comentado, y todas las decisiones tomadas y el trabajo desarrollado deben documentarse suficientemente en celdas de texto.

- La entrega en PRADO está configurada para permitir sucesivas entregas de la práctica. Desde este punto de vista, se recomienda subir versiones de la práctica a medida que se van realizando los distintos ejercicios propuestos, y no dejarlo todo para el final, dado que es altamente improbable que se extienda la fecha de entrega.

- Reiterar que es obligatorio documentar las valoraciones y decisiones adoptadas en el desarrollo de cada uno de los apartados. Debe incluirse también una valoración razonada sobre la calidad de los
resultados obtenidos. Sin esta documentación, se considera que el trabajo NO ha sido presentado.

- Se debe respetar la estructura y secciones del Notebook. Esto servirá para agilizar las correcciones, así como para identificar con facilidad qué ejercicio/apartado se está respondiendo.

- El codigo NO puede escribir nada a disco.

- Se espera que el código siempre lea de un directorio llamado 'drive/MyDrive/Colab Notebooks/datos/', situado dentro del directorio donde se desarrolla y ejecuta la práctica. No se admiten excepciones a esta ruta de acceso a los datos.

- Una entrega es apta para ser corregida si se puede ejecutar de principio a fin sin errores.

- No es válido usar opciones en las entradas (es decir, utilizar el comando `input`, por ejemplo, para que el usuario escoja el valor de las variables para ejecutar el programa). Para ello, se deben fijar al comienzo los valores
por defecto que se consideren óptimos o que se soliciten en el enunciado.

- El código debe estar obligatoriamente comentado explicando lo que realizan los distintos apartados y/o bloques.

- Se entrega solamente este Notebook, y no los datos empleados.


---

<font color='blue'>Este trabajo  se centra en el ajuste y selección del mejor predictor lineal para un conjunto de datos dado. Para ello, se recomienda el uso de la librería Scikit-Learn (https://scikit-learn.org/). Esta librería contiene funciones de alto nivel que pueden ser muy útiles para el desarrollo de la práctica. En cualquier caso, para cada función de Scikit-Learn que se use, debe explicar por qué es necesario su uso, así como explicar su funcionamiento y el significado de todos sus parámetros. En relación con este punto, los valores por defecto en la librería no se consideran elecciones justificadas $\textit{a priori}$ y, al igual que en el resto de la práctica, decisiones sin justificación y resultados sin interpretación no serán considerados válidos.
"""

#Para acceder a nuestros ficheros de Google Drive
from google.colab import drive
drive.mount('/content/drive')
# La carpeta datos (que contiene OnlineNewsPopularity.csv, OnlineNewsPopularity.names)
# debe estar en vuestro Drive, dentro de la carpeta 'Colab Notebooks'
ruta = 'drive/MyDrive/Colab Notebooks/datos/'

# Función auxiliar que permite la lectura de un fichero y lo estructura en un
# dataframe
def leer_datos(archivo, separador=";", header=None): # Por defecto el separador es ;
    # Los datos se guardan en un dataframe
    """
    IMPORTANTE. Al generar un dataframe con pandas usando
    la lectura de ficheros, la primera fila actuará como la cabecera del mismo
    Hay que indicarle que no hay cabecera si el fichero no la tiene.
    En este caso, el fichero de regresión contiene una primera fila como la cabecera
    """
    if header is None:
      datos = pd.read_csv(archivo, sep=separador, header=None, skipinitialspace=True)
    else:
      datos = pd.read_csv(archivo, sep=separador, skipinitialspace=True)

    return datos

# Operaciones con dataframes

# Une vectores de datos y objetivo en un dataframe
def join_(X,Y, cols=None):
  joined_data = np.column_stack((X, Y))

  # Crear un DataFrame de train
  return pd.DataFrame(joined_data, columns=cols)

# Une dataframes de datos y objetivo
def rejoin_(X,Y, axis=1):
  return pd.concat([X,Y], axis=axis, join='inner')

# Obtiene componentes X o Y de un dataframe
def X_(X):
  return X.iloc[:, :-1]
def Y_(X):
  return X.iloc[:, -1]

# Función que separa la muestra en sus características y objetivo
def separar_datos(data):
    valores = data.values

    # Todas las columnas excepto la última son los valores a usar (X)
    X = valores[:, 0:-1]

    # La última columna son los valores a predecir (Y)
    Y = valores[:, -1]

    return X, Y

# Cuenta el número de veces que aparece un rango de articulos compartidos y hace un muestreo
# Servirá para ver qué tan balanceados están los datos
def show_histogram(data, titulo, xlabel, ylabel, fontsize=12):
    fig, ax = plt.subplots(figsize=(20,10))

    # Obtener los valores de la columna objetivo
    ctarget = data['CARAVAN'].value_counts()

    # Calcular total
    total = ctarget.sum()

    # Calcular el porcentaje de datos en cada barra
    porcentaje = ctarget / total * 100

    # Crear el histograma utilizando seaborn
    sns.barplot(x=ctarget.index, y=ctarget.values)

    #plt.xticks(rotation=0)  # Rotación de 90 grados para las etiquetas del eje x

    # Mostrar el porcentaje en cada barra del histograma
    for i, v in enumerate(porcentaje):
      ax.text(i, int(ctarget.values[i]/2), f'{v:.2f}%', ha='center', va='bottom', rotation='horizontal', fontsize=fontsize)

    # Etiquetas y título
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(titulo + '. Intervalos de ' + str(intervalo) + ' en ' + str(intervalo))

    # Mostrar el histograma
    plt.show()

# Calculo de variables continuas
# display(regress_data.describe()) # muestra una tabla similar
def crear_tabla_valores(Train):
  media = Train.mean()   # Media
  mediana = Train.median()   # Mediana
  desviacion_tipica = Train.std()   # Desviación estándar
  minimo = Train.min()   # Mínimo
  maximo = Train.max()   # Máximo
  per = [0.1, 0.25, 0.50, 0.75, 0.9];   # Percentiles
  percentiles = Train.quantile(per)

  # Crea un nuevo DataFrame con los valores calculados
  tabla_valores = pd.DataFrame({
      'Media': media,
      'Mediana': mediana,
      'Desviación típica': desviacion_tipica,
      'Mínimo': minimo,
      'Máximo': maximo
  })

  # Agrega los percentiles al DataFrame
  for p in per:
      tabla_valores[f'Percentil {p*100}'] = percentiles.loc[p]

  return tabla_valores

"""#### <font color='blue'>1)  Analizar y describir adecuadamente el problema a resolver. Identificar los elementos $X$, $Y$ and $f$ del problema, y describirlos en detalle. 0.5 puntos.

El problema a resolver en el conjunto de datos **Insurance Company Benchmark** es predecir la prima de seguros para diferentes perfiles de clientes basados en un conjunto de atributos relacionados. Este conjunto de datos consta de un total de 9000 instancias (artículos) y 86 atributos.

El conjunto de datos Insurance Company Benchmark contiene información sobre diferentes perfiles de clientes, como edad, género, estado civil, ingresos, número de hijos, tipo de trabajo, entre otros. También incluye atributos relacionados con la póliza de seguros, como el tipo de cobertura, la duración de la póliza, la suma asegurada, entre otros.

El objetivo principal es utilizar estos atributos para predecir la prima de seguros para cada perfil de cliente. La prima de seguros es el monto que un cliente debe pagar periódicamente a la compañía de seguros para mantener su póliza activa.

Por lo tanto, la función objetivo del problema se define como f: $\mathcal{X} \rightarrow \mathcal{Y}$, donde $\mathcal{X}$ representa el conjunto de atributos del perfil del cliente y $\mathcal{Y}$ representa la prima de seguros correspondiente.

El objetivo final es construir un modelo de aprendizaje automático que pueda aprender a partir de los datos proporcionados y realizar predicciones precisas sobre la prima de seguros para perfiles de clientes no vistos. Esto permitirá a las compañías de seguros tener una estimación más precisa de las primas para diferentes perfiles de clientes y ajustar sus estrategias de precios en consecuencia. Además, también puede ayudar a los clientes a comprender mejor cómo se determina su prima de seguros y tomar decisiones informadas al elegir una póliza.

![image.png](data:image/png;base64,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)
"""

# Lectura de datos y previsualizacion
file_data = ruta + "ticdata2000.txt" # Entrenamiento
file_eval = ruta + "ticeval2000.txt" # Test sin target
file_tgts = ruta + "tictgts2000.txt" # Targets test

# Leer los datos
classification_data = leer_datos(file_data, "\t")
classification_eval = leer_datos(file_eval, "\t")
classification_tgts = leer_datos(file_tgts, "\t")

# Asignamos el número de columna en test
classification_tgts = classification_tgts.rename(columns={0: 85})

print(f"Dimensiones del dataset de entrenamiento (ejemplos, atributos): {classification_data.shape}")
print(f"Dimensiones del dataset de evaluación (ejemplos, atributos): {classification_eval.shape}")
print(f"Dimensiones del cojunto de target (ejemplos): {classification_tgts.shape}")

# Concatenar datos de evaluacion con la etiqueta
full_classification_eval = rejoin_(classification_eval, classification_tgts)
print(f"\nDimensiones del dataset de test (ejemplos, atributos): {full_classification_eval.shape}")

# Concatenar datos de entrenamiento y test
full_classification_data = rejoin_(classification_data, full_classification_eval, axis=0)

# Mezclar las filas aleatoriamente
data_class = full_classification_data.sample(frac=1, random_state=33)

# Limpiar indices
data_class = data_class.reset_index(drop=True)

# Asignar nombres a las columnas
# Lo escribiría en un fichero y lo leería de forma externa pero no se permite
# escribir nada

atributos = {
  0 : "MOSTYPE", # Customer Subtype see L0
  1 : "MAANTHUI", # Number of houses 1 � 10
  2 : "MGEMOMV", # Avg size household 1 � 6
  3 : "MGEMLEEF", # Avg age see L1
  4 : "MOSHOOFD", # Customer main type see L2
  5 : "MGODRK", # Roman catholic see L3
  6 : "MGODPR", # Protestant ...
  7 : "MGODOV", # Other religion
  8 : "MGODGE", # No religion
  9 : "MRELGE", # Married
  10 : "MRELSA", # Living together
  11 : "MRELOV", # Other relation
  12 : "MFALLEEN", # Singles
  13 : "MFGEKIND", # Household without children
  14 : "MFWEKIND", # Household with children
  15 : "MOPLHOOG", # High level education
  16 : "MOPLMIDD", # Medium level education
  17 : "MOPLLAAG", # Lower level education
  18 : "MBERHOOG", # High status
  19 : "MBERZELF", # Entrepreneur
  20 : "MBERBOER", # Farmer
  21 : "MBERMIDD", # Middle management
  22 : "MBERARBG", # Skilled labourers
  23 : "MBERARBO", # Unskilled labourers
  24 : "MSKA", # Social class A
  25 : "MSKB1", # Social class B1
  26 : "MSKB2", # Social class B2
  27 : "MSKC", # Social class C
  28 : "MSKD", # Social class D
  29 : "MHHUUR", # Rented house
  30 : "MHKOOP", # Home owners
  31 : "MAUT1", # 1 car
  32 : "MAUT2", # 2 cars
  33 : "MAUT0", # No car
  34 : "MZFONDS", # National Health Service
  35 : "MZPART", # Private health insurance
  36 : "MINKM30", # Income < 30.000
  37 : "MINK3045", # Income 30-45.000
  38 : "MINK4575", # Income 45-75.000
  39 : "MINK7512", # Income 75-122.000
  40 : "MINK123M", # Income >123.000
  41 : "MINKGEM", # Average income
  42 : "MKOOPKLA", # Purchasing power class
  43 : "PWAPART", # Contribution private third party insurance see L4
  44 : "PWABEDR", # Contribution third party insurance (firms) ...
  45 : "PWALAND", # Contribution third party insurane (agriculture)
  46 : "PPERSAUT", # Contribution car policies
  47 : "PBESAUT", # Contribution delivery van policies
  48 : "PMOTSCO", # Contribution motorcycle/scooter policies
  49 : "PVRAAUT", # Contribution lorry policies
  50 : "PAANHANG", # Contribution trailer policies
  51 : "PTRACTOR", # Contribution tractor policies
  52 : "PWERKT", # Contribution agricultural machines policies
  53 : "PBROM", # Contribution moped policies
  54 : "PLEVEN", # Contribution life insurances
  55 : "PPERSONG", # Contribution private accident insurance policies
  56 : "PGEZONG", # Contribution family accidents insurance policies
  57 : "PWAOREG", # Contribution disability insurance policies
  58 : "PBRAND", # Contribution fire policies
  59 : "PZEILPL", # Contribution surfboard policies
  60 : "PPLEZIER", # Contribution boat policies
  61 : "PFIETS", # Contribution bicycle policies
  62 : "PINBOED", # Contribution property insurance policies
  63 : "PBYSTAND", # Contribution social security insurance policies
  64 : "AWAPART", # Number of private third party insurance 1 - 12
  65 : "AWABEDR", # Number of third party insurance (firms) ...
  66 : "AWALAND", # Number of third party insurane (agriculture)
  67 : "APERSAUT", # Number of car policies
  68 : "ABESAUT", # Number of delivery van policies
  69 : "AMOTSCO", # Number of motorcycle/scooter policies
  70 : "AVRAAUT", # Number of lorry policies
  71 : "AAANHANG", # Number of trailer policies
  72 : "ATRACTOR", # Number of tractor policies
  73 : "AWERKT", # Number of agricultural machines policies
  74 : "ABROM", # Number of moped policies
  75 : "ALEVEN", # Number of life insurances
  76 : "APERSONG", # Number of private accident insurance policies
  77 : "AGEZONG", # Number of family accidents insurance policies
  78 : "AWAOREG", # Number of disability insurance policies
  79 : "ABRAND", # Number of fire policies
  80 : "AZEILPL", # Number of surfboard policies
  81 : "APLEZIER", # Number of boat policies
  82 : "AFIETS", # Number of bicycle policies
  83 : "AINBOED", # Number of property insurance policies
  84 : "ABYSTAND", # Number of social security insurance policies
  85 : "CARAVAN" # Number of mobile home policies 0 - 1]
}

# Utiliza el método rename() para asignar los nombres de columna al DataFrame
data_class = data_class.rename(columns=atributos)

# Visualizar datos
display(data_class.head())

# Podemos ver más sobre cada atributo: tipo y valores nulos
# En el dataset nos dicen que no hay valores faltantes
print("\n\tComo el shape del dataframe contiene las mismas columnas se puede intuir que no hay datos erroneos")
print(data_class.info())

print("Se consideran MOSTYPE y MOSHOOFD como categóricas, ahora se explica por qué.")
categoricas = ["MOSTYPE", "MOSHOOFD"] # Identifican tipo y subtipo de cliente
# El resto de variables son numéricas aunque se podrían considerar ciertas categorías

"""Tenemos 9822 ejemplos y 86 atributos. La última (`CARAVAN`) es el valor a predecir. Hay ciertos bloques de datos que se identifican:

- **Tipo y subtipo de cliente:** Esta categoría proporciona información sobre los diferentes tipos y subtipos de clientes según el segmento al que pertenecen.
Hay 2 atributos en el bloque: MOSTYPE y MOSHOOFD que dada su naturaleza se consideran **CATEGÓRICOS**.

- **Información sobre el hogar:** Esta categoría incluye atributos relacionados con el hogar, como el número de casas en el hogar, el tamaño promedio o si es de alquiler o no.

- **Religión:** Estos atributos indican la distribución de las creencias religiosas en la región, como el porcentaje de católicos romanos, protestantes, personas con otras religiones y personas sin religión.

- **Estado civil:** Esta categoría muestra la composición del estado civil de los individuos, incluyendo el porcentaje de personas casadas, viviendo juntas, en otras relaciones y solteras.

- **Educación:** Estos atributos reflejan el nivel educativo de las personas, como el porcentaje de personas con educación de alto nivel, medio nivel y bajo nivel.

- **Estatus social:** Esta categoría proporciona información sobre el estatus social de los individuos, como el porcentaje de personas en una posición social alta, emprendedores, granjeros y en puestos de gerencia intermedia.

- **Coche:** Estos atributos describen la propiedad de automóviles en los hogares, como el porcentaje de hogares con 1 automóvil, 2 automóviles o sin automóviles.

- **Salud:** Estos atributos indican la contribución a servicios de salud, como el porcentaje de personas que contribuyen al servicio de salud nacional y tienen seguro de salud privado.

- **Ingresos:** Esta categoría incluye atributos relacionados con los ingresos de las personas, como diferentes rangos de ingresos, ingreso promedio, etc.

- **Contribución a pólizas:** Estos atributos representan la contribución a diferentes tipos de pólizas, como pólizas privadas de terceros, pólizas de terceros para empresas, pólizas de terceros para agricultura, etc.

- **Número de pólizas:** Esta categoría proporciona información sobre el número de pólizas que poseen los individuos en diferentes categorías, como pólizas de automóviles, pólizas de vida, pólizas de propiedad, etc.

Estos bloques de información nos brindan una visión completa de los diferentes aspectos demográficos, económicos y de estilo de vida de los clientes en el conjunto de datos Insurance Company Benchmark.
"""

# antes es necesario convertir las variables categóricas en numéricas
print(f"{categoricas}")

display(data_class)
target = Y_(data_class)

X_data_class = pd.get_dummies(X_(data_class), columns = categoricas, drop_first = True)

data_class = rejoin_(X_data_class, target)
print("Se han transformado los datos...\n")
display(data_class.head())

# Separamos los datos del atributo objetivo
X, Y = separar_datos(data_class) # Primero se separa en X e Y

# Dividir los datos en training y test usando la libreria scikit
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle=True)

# Crear dataframes de test y train
train = join_(X_train, Y_train, data_class.columns)
test = join_(X_test, Y_test, data_class.columns)

# Visualizamos el objetivo
title = "Número de clientes con seguro de caravana"
xlabel = "Tiene seguro de caravana"
ylabel = "Numero de ejemplos"
intervalo = 1
percentil = 100

show_histogram(train, title , xlabel, ylabel, 14)

print("Estan desbalanceados. La mayoría no tienen seguro")
# Y_(data_class).hist(figsize=(20,20))
# plt.show()

data_class.iloc[:,0:60].hist(figsize=(20,20))
plt.tight_layout()
plt.show()

# Muestra las variables continuas originales del atributo objetivo
tablaOriginal = crear_tabla_valores(train)
print("Información relevante del atributo objetivo original")
display(tablaOriginal.tail(1))

# Visualizamos la correlacion de los datos

# Calcular la matriz de correlación de Pearson con las variables continuas
pearson_corr = train.corr(method='pearson')

# Calcular la matriz de correlación de Spearman
#spearman_corr = train.corr(method='spearman') # Redundante

# Crear un mapa de calor de la matriz de correlación de Pearson
plt.figure(figsize=(10, 8))
sns.heatmap(pearson_corr, annot=False, cmap='coolwarm', annot_kws={"size": 8})
plt.title('Matriz de Correlación (Pearson)')
plt.show()

# Obtenemos variables con una alta correlación
def get_most_correlated(pearson_corr, threshold):
  # Crear un diccionario para almacenar los pares de columnas con correlación superior a 0.9
  pares_corr = {}

  # Obtener las dimensiones del DataFrame
  num_filas, num_columnas = pearson_corr.shape

  # Iterar sobre las columnas del DataFrame
  for i in range(num_columnas):
      for j in range(i+1, num_columnas):
          # Verificar si la correlación es mayor a 0.95
          if abs(pearson_corr.iloc[i, j]) > threshold:
              # Almacenar el par de columnas con la correlación en el diccionario
              columna_1 = pearson_corr.columns[i]
              columna_2 = pearson_corr.columns[j]
              pares_corr[(columna_1, columna_2)] = pearson_corr.iloc[i, j]

  # Mostrar los pares de columnas con correlación superior a 0.9
  print("Numero de pares correlacionados: ", len(pares_corr))
  for pares, correlacion in pares_corr.items():
      columna_1, columna_2 = pares
      print(f"Columna 1: {columna_1}, Columna 2: {columna_2}, Correlación: {correlacion}")

  return pares_corr

threshold = 0.9
# Calcular la matriz de correlación de Pearson
pearson_corr = train.corr(method='pearson')

# Obtenemos los pares más correlados
pares_corr = get_most_correlated(pearson_corr, threshold)

print("""\nPodemos observar que algunos atributos de pago de seguro vs numero de seguros
están muy relacionados\n""")

print("Atributos originales en los datos: ", train.shape[1])
# Eliminamos correlados
for par in pares_corr:
    columna_eliminar = par[0]
    train = train.drop([columna_eliminar], axis=1, errors='ignore')
    test = test.drop([columna_eliminar], axis=1, errors='ignore')

print("Atributos tras quitar correlados en los datos: ", train.shape[1])

# Comprobamos
print("\nComprobamos que se eliminan correctamente.")

# Recalcular la matriz de correlación de Pearson
pearson_corr = train.corr(method='pearson')

# Obtenemos los pares más correlados
pares_corr = get_most_correlated(pearson_corr, threshold)

# Crear un mapa de calor de la matriz de correlación de Pearson
plt.figure(figsize=(10, 8))
sns.heatmap(pearson_corr, annot=False, cmap='coolwarm', annot_kws={"size": 8})
plt.title('Matriz de Correlación (Pearson). Correladas eliminadas')
plt.show()
# Iterar sobre las columnas del DataFrame

"""#### <font color='blue'>2)  Identificar qué conjuntos de hipótesis se emplearán y justificar dicha elección. 0.25 puntos.

Para la realización de la práctica se pide principalmente aplicar modelos lineanes. De los tres modelos propuestos, Regresión Lineal, Regresión Logística y Perceptron+Pocket vamos a aplicar la Regresión Logística y el Perceptron usando la versión Pocket.

La Regresión Logística permite estimar la probabilidad de una variable cualitativa binaria en función de una variable cuantitativa. Es por ello que el uso de este modelo es una de las principales aplicaciones para la clasificación binaria. En este caso, claramente estamos ante un problema de
**Clasificación Binaria** ya que el resultado buscado es hallar <font color='blue'>**YES** </font> o <font color='red'>**NO** </font>. No deja de ser una aplicación de Regresión, por tanto la asignación final se hace en función de las probabilidades predichas.

La decisión de aplicar la Regresión Logística y no la Lineal pese a ser posible ajustar matemáticamente la clasificación por Mínimos Cuadrados es que esta aproximación puede obtener valores de Y menores que 0, rompiendo así el hecho de que el rango debe estar entre [0, 1]. La Regresión Logística, en cambio, transforma este valor comprendiendo siempre el resultado en este rango.

$$
\sigma(x)=\frac{1}{1+e^{-x}} \quad \text{Función sigmoide}
$$

Por otro lado tenemos el uso del Perceptrón, que, podría decirse que el algoritmo de aprendizaje para clasificación binaria por excelencia. Podría incluso considerarse una especie de red neuronal muy simple, aunque no es el tema que concierne. Lo que hace este algoritmo es analizar una entrada
y predecir una salida. Para ello lo que hace es calcular una suma ponderada de las entradas y un sesgo. Esto sería la activación. Depende del valor de la Activación, retornará un valor 0 o un valor 1, si ocurre que esta es menor o igual a 0, o mayor que 0 respectivamente. Para el cálculo de los
coeficientes, se aplica el SGD (**Gradiente Descendente Estocástico**)

Este algoritmo tiene un inconveniente, y es que, además de tener un cómputo lento, es posible que nunca converja, por tanto hay que establecer un máximo de épocas (iteraciones) y un promedio de error como cota. Además necesita que queden fijados antes de ejecutarse unos pesos (coeficientes),
los cuales irán ayudando a calcular las salidas. Por convención, se inicializan a un valor muy pequeño.

#### <font color='blue'>3)  Si la base de datos define conjuntos de training y test, únalos en un solo conjunto y genere sus propios conjuntos. Describa y justifique el mecanismo de partición. 0.75 puntos.

Esta vez nos dan 3 ficheros diferentes:
- ticdata2000.txt: es el conjunto de entrenamiento
- ticeval2000.txt: es el conjunto de test
- tictgts2000.txt: contiene las etiquetas de test

El procedimiento de unión y separación se realiza en el punto 1, se detalla a continuación.

Primero se leen los 3 ficheros de forma independiente, se unen test con las etiquetas y posteriormente se une con train. Se realiza un mezclado de datos y se pasa al procedimiento de particionado.

Para realizar dicha partición se ha tomado el conjunto completo de datos y se han elegido qué porcentajes del total formarán parte de una parte y de otra. Se ha elegido que el 20 % formará parte del conjunto Test, mientras que el restante 80 % lo será del Train quedando:

- Train. 7857 elementos del conjunto de datos.
- Test. 1965 elementos.

Para hacer esto, en el primer apartado se ha hecho uso de la función de `sklearn`:

 `train_test_split(X, Y, test_size = 0.2, shuffle=True)`

 Indicando en sus parámetros el mezclado de datos mediante shuffle, de forma que el 80 % no sea los primeros elementos y el resto los últimos, si no que antes haga una mezcla de los mismos.

Dentro del conjunto de entrenamiento podemos aplicar diferentes técnicas como el leave one out, hold out o cross validation o una mezcla de varios. Vamos a analizar cada uno:

-  **Cross Validation (CV)**: En lugar de dividir el conjunto de datos en una única partición de entrenamiento y prueba, cross validation divide el conjunto de datos en k particiones o "folds" de tamaño similar. El objetivo es evaluar el rendimiento del modelo de forma más robusta, ya que se utiliza la totalidad de los datos en múltiples combinaciones de entrenamiento y prueba. Esto permite obtener una estimación más confiable del rendimiento del modelo y evaluar cómo se generaliza a datos no vistos.

- **Leave one out**: es una técnica de validación cruzada muy costosa computacionalmente, ya que implica entrenar el modelo tantas veces como el número de muestras en el conjunto de entrenamiento. En nuestro caso que hay unas 9.000 instancias de entrenamiento no es recomendable.

- **Hold out**: implica dividir el conjunto de datos en dos partes: entrenamiento y validación. Si los datos presentan una distribución no uniforme o existe una variabilidad significativa en los datos, la partición realizada en hold out puede introducir un sesgo en la evaluación del modelo. Y como hemos visto, nuestros datos tienen un desbalanceo importante por lo que no es recomendable usarlo. En cambio, el uso de cross validation permite evaluar el rendimiento del modelo en diferentes subconjuntos de datos, lo que ayuda a mitigar el impacto de esa variabilidad.

Los motivos extra por los que usar cross validation son:

 - Mayor aprovechamiento de los datos: ya que permite utilizar la totalidad de los datos de entrenamiento en múltiples iteraciones, lo que resulta en un mejor aprovechamiento del conjunto de entrenamiento disponible.

- Evaluación más fiable del modelo: al realizar múltiples particiones del conjunto de datos y promediar los resultados, CV proporciona una estimación más fiable del rendimiento del modelo. Permite evaluar cómo se generaliza el modelo en diferentes configuraciones de los datos y ayuda a mitigar el impacto de una partición de datos específica en los resultados finales.

- Ajuste de hiperparámetros: permite evaluar diferentes combinaciones de hiperparámetros en múltiples divisiones del conjunto de entrenamiento, lo que ayuda a seleccionar los mejores hiperparámetros de manera más confiable.

Se ha decidio utilizar CV. Para aplicarlo, se ha importado la función cross_val_score de Sklearn

`pred = cross_val_predict(classification, X, y, cv=5)`

Una vez obtenida la predicción se llama a la función propia de evaluate_model para calcular todas las métricas deseadas.

La función cross_val_score tiene varios parámetros que se pueden ajustar para personalizar el proceso de validación cruzada. Aquí tienes una descripción de los parámetros más importantes:

- estimator: Es el estimador o modelo que se utilizará para realizar la validación cruzada. Puede ser cualquier objeto que implemente los métodos fit y predict. En nuestro problema se usará la regresión logística.

- X: Son los datos de entrada o características que se utilizarán para entrenar y evaluar el modelo.

- y: Son las etiquetas o valores objetivo correspondientes a los datos de entrada.

- cv: Especifica la estrategia de validación cruzada a utilizar. Puede ser un entero para indicar el número de folds, por ejemplo cv=5 para 5-fold cross-validation.
"""

# la separacion de train se realiza al principio en el apartado 1

print("\tTamaño del Conjunto")
print("\t\t", X.shape)

print("\n\tTamaño del Train")
print("\t\t", X_train.shape)

print("\n\tTamaño del Test")
print("\t\t", X_test.shape)

# El cross validation se aplica en el apartado 7
# scores = cross_val_predict(classification, X, y, cv=5, scoring='accuracy')

"""#### <font color='blue'>4)  Justifique todos los detalles del preprocesado de los datos (codificación, transformación, normalización, etc). Es decir, todas las manipulaciones sobre los datos iniciales que nos permitan fijar el conjunto de vectores de características que se usarán en el entrenamiento. 1 punto.

<font color='blue'>Nota: Las transformaciones no-lineales de las variables pueden definirse a partir de las potencias y
productos de potencias de las variables originales, conjuntos de polinomios ortogonales, etc. Si se
usan transformaciones no polinómicas de las variable como $log$, $\sqrt{()}$, $sin$, etc, debe justificar el
interés de las mismas.

En primer lugar, lo que se ha hecho es transformar las variables categóricas a variables numéricas. Los algoritmos matemáticos no pueden incluir objetos o cadenas como entrada a la hora de entrenar, es por eso que se realiza dicha transformación. Para conseguirla, ya que el modelo está cargado en una estructura de datos de tipo Pandas Dataframe es fácil realizar esto mediante la
función `get_dummies(datas, columns = categoricas, drop first = True)`. A esta función se le pasa el conjunto de datos (aun sin dividir en train y test). Además hay que pasar las columnas que son categóricas, ya que por sí solo no sabe cuales son. Por último, para no tener las columnas anteriores
categóricas se usa el parámetro drop first a true de forma que elimina la columna anterior categórica y deja la nueva numérica. Para obtener cuáles son las columnas que tienen datos categóricos miramos la documentación y encontramos que **MOSTYPE** y **MOSHOOFD** son categorías de cliente. Con todo esto se procede a su eliminación.

El siguiente paso en el preprocesamiento es eliminar aquellos datos sin varianza. Es una opción esencial para aumentar la calidad del modelo. Para esto se usa mi función propia remove_non_variability. Esta función solo trabaja con datos numéricos, así que es por ello que en primer lugar se transformaron las variables. El valor que recibe es la cota que se permite de varianza, es decir, aquellas características con un valor MENOR a este, quedan fuera del conjunto.

Sin embargo, antes de realizar esto es OBLIGATORIO normalizar los datos. Esto se realiza así debido a que todos los datos deben estar en la misma escala, si no la varianza puede estimarse de forma incorrecta entre qué es un valor alto y cual uno bajo. Para la normalización de datos, al igual que ocurrió en la Regresión se usa la función de sklearn StandardScaler().fit transform(X).
"""

def normalize(XTrain, XTest):
    # Crear un objeto StandardScaler
    scaler = StandardScaler()

    # Calcular la media y la desviación estándar del conjunto de entrenamiento
    scaler.fit(XTrain)

    # Aplicar la normalización a los conjuntos de entrenamiento y prueba utilizando los valores de entrenamiento
    train_norm = scaler.transform(XTrain)
    test_norm = scaler.transform(XTest)

    # Convertir los conjuntos normalizados de vuelta a DataFrames con los mismos nombres de columnas
    train_norm = pd.DataFrame(train_norm)
    test_norm = pd.DataFrame(test_norm)

    return train_norm, test_norm

# Normalizar datos
print("\n3. Se normalizan los datos mediante MinMaxScaler")
X_train_norm, X_test_norm = normalize(X_train, X_test)

# Mostrar las primeras filas del conjunto de entrenamiento original y normalizado
display(pd.DataFrame(X_train).head())
display(X_train_norm.head())

def remove_non_variability(XTrain, XTest, threshold=0):
    # Crear un objeto StandardScaler
    nonvariable = VarianceThreshold(0.6)

    # Calcular la media y la desviación estándar del conjunto de entrenamiento
    nonvariable.fit(XTrain)

    # Aplicar la normalización a los conjuntos de entrenamiento y prueba utilizando los valores de entrenamiento
    Xtrain_nv = nonvariable.transform(XTrain)
    Xtest_nv = nonvariable.transform(XTest)

    return Xtrain_nv, Xtest_nv

print("Dimension antes de eliminar no variabilidad:",X_train_norm.shape)

# Eliminar datos sin variabilidad (no son discriminantes)
X_train_nv, X_test_nv = remove_non_variability(X_train_norm, X_test_norm)

print("Dimension tras eliminar no variabilidad: ", X_train_nv.shape)

"""Tras normalizar y tratar de eliminar aquellos datos sin variablidad, se procede a eliminar los Outliers. Estos son aquellos valores que “mienten” sobre la respuesta buscada. Los Outliers pueden terminar afectando notoriamente a la aplicación de PCA, de forma que si no se contemplan antes, se eliminen muchas más complejidad que la que debería eliminarse. Para ello se usa la función `OneClassSVM(nu=0.01)` de svm (Support Vector Machine). Esta función genera el modelo permitiendo un máximo de error de entrenamiento que es la variable nu y aplicando su función `fit_predict(X)` devuelve aquellos elementos que se consideran Outliers, es decir, anomalías en los datos. Una vez estos se eliminen se podría decir que los datos contienen todos la misma distribución
normal. Tras realizar la búsqueda de outliers el conjunto de datos se ha reducido de 7857 instancias a 7664.
"""

print("Los outliers pueden afectar notoriamente al aplicar PCA.")
print("Vamos a identificar esos outliers y eliminarlos\n")

# Identificar outliers en el conjunto de entrenamiento usando One-Class SVM
outlrs = OneClassSVM(nu=0.01)
outlrs.fit(X_train_nv)

# Predecir outliers en los conjuntos de entrenamiento y prueba
yhat_train = outlrs.predict(X_train_nv)
yhat_test = outlrs.predict(X_test_nv)

# Seleccionar filas que NO son outliers
mask_train = yhat_train != -1
mask_test = yhat_test != -1

# Filtrar el conjunto de entrenamiento y prueba eliminando los outliers
X_train_outlrs, Y_train_outlrs = X_train_nv[mask_train, :], Y_train[mask_train]
X_test_outlrs, Y_test_outlrs = X_test_nv[mask_test, :], Y_test[mask_test]

print("\n\tDimensión de los datos antes de eliminar los outliers")
print("\t\t", X_train_nv.shape)

print("\n\tDimensión de los datos tras eliminar los outliers")
print("\t\t", X_train_outlrs.shape)

"""Ahora ya sí, tras transformar los datos y dividir en Train y Test los mismos, se aplica PCA.

Tal y como se menciono en la Regresión, este sirve para reducir la complejidad del problema. Tras aplicarlo queda como resultado:
"""

def apply_PCA(XTrain, XTest, value):
  print("\nDimensiones antes de aplicar PCA", XTrain.shape[1])
  # Crear instancia del modelo PCA con el valor especificado
  pca = PCA(value)

  # Ajustar el modelo PCA a los datos de entrenamiento
  pca.fit(XTrain)

  # Transformar los datos de entrenamiento utilizando el modelo PCA
  XTrain = pca.transform(XTrain)

  print("\nDimensiones después de aplicar PCA", XTrain.shape[1])

  # Transformar los datos de prueba utilizando el modelo PCA
  XTest = pca.transform(XTest)

  return XTrain, XTest

# Aplicar PCA
X_train_prep, X_test_prep = apply_PCA(X_train_outlrs, X_test_outlrs, 0.99)

# Combinar X e Y
train_prep = join_(X_train_prep , Y_train_outlrs)
test_prep = join_(X_test_prep, Y_test_outlrs)

# Obtenemos los conjuntos finales para probar los modelos
X_train_prep = X_(train_prep)
Y_train_prep = Y_(train_prep)
X_test_prep = X_(test_prep)
Y_test_prep = Y_(test_prep)

print(f"\nDimensiones originales: {train.shape}")
print(f"Dimensiones finales: {train_prep.shape}")

"""#### <font color='blue'>5)  Justifique las métricas de error y la función de pérdida a usar. Discutir su idoneidad para el problema. 0.5 puntos.

Para evaluar el modelo se ha usado la propia función **score** que proporciona el modelo de Regresión Logística, pero además se ha calculado la precisión del modelo mediante la función **accuracy score (Y, predictions)** de sklearn. Esta accuracy básicamente lo que hace es calcular el número de predicciones correctas. No obstante, no es del todo fiable, ya que hay que ver también si
ese valor se corresponde con la precisión real de cada clase, es decir, supóngase que hay un conjunto de datos donde para una clase se han acertado el 99 % pero para otra un 0 %, y la precisión que devuelve el modelo en su conjunto es del 99 % o un valor muy próximo a ese. En realidad no es un
valor representativo, ya que de la clase 2 no ha sido capaz de clasificar nada.

Esto es muy común cuando los datos están muy desbalanceados, de forma que, por ejemplo, habiendo dos clases (un problema binario) para la clase A hay 1000 muestras, mientras que para la clase B hay solo 10. Sería mucho pedirle al modelo que fuese capaz de aprender a clasificar valores para la clase B cuando apenas tiene instancias suficientes de las que aprender. Es por ello, que además de mostrar el accuracy se muestra también la Matriz de Resultados donde se muestra toda la precisión e información de cada clase, y además la Matriz de Confusión. Este última permite comprobar cuántos **Falsos Negativos** y cuántos **Falsos Positivos** han ocurrido durante la predicción usando el conjunto de Test. Para obtener dichas matrices, de nuevo se importan de la librería sklearn los métodos **classification report(Y, predictions) y confusion matrix(Y, predictions)**

La **Matriz de Resultados** muestra las siguientes métricas:

- **Accuracy**. Es el número total de predicciones acertadas dividido por el número total de elementos. Como se ha explicado, hay que tener cuidado con este valor, por sí solo, puede que no aporte nada.

- **Precision**. Aunque en español el término significa lo mismo que accuracy no significan lo mismo. Esta precisión hace referencia a cuánto de confiable es el modelo para ser capaz de responder si un punto pertenece a una clase.

- **Recall**. Expresa como de bien es capaz el modelo de detectar una clase.

- **F1-Score**. Combina en forma de media la precision y el recall. Cuando más próximo a 0 en un rango [0, 1] (como los demás valores) peor ha sido el resultado.

#### <font color='blue'>6)  Discuta todos los parámetros y el tipo de regularización usada en el ajuste de los modelos seleccionados. Justificar la idoneidad de la regularización elegida. 1 punto.

Respecto la Regularización, en este caso no es posible aplicar Lasso, a diferencia de lo que ocurría en el problema de Regresión que era posible aplicar ambas. ¿Por qué? Es sencillo. Lasso optimiza mediante Mínimos Cuadrados, y por definición, por tanto, no es posible aplicar Lasso a
en una función logística. Al menos no es aplicable de forma standard, para poder aplicarlo se debe configurar un parámetro llamado solver en la función y darle un valor liblinear o SAGA. Esta es la única forma de aplicar la Regularización Lasso.

El otro tipo de Regularización que se ha aplicado ha sido Ridge. A diferencia de lo comentado en la parte de Regresión, para poder aplicar estos tipos de Regularización, esta vez no se importan los métodos desde sklearn si no que se hace mediante la parametrización de la llamada que crea el modelo de Regresión Logística, es decir `LogisticRegression(penalty=pen, solver=solvr, max_iter=1500)`.

- **Penalty**. Mediante este parámetro se indica el tipo de Regularización a aplicar, siendo L1 Lasso y L2 Ridge.

- **Solver**. Es la configuración que, en este caso, eligiendo liblinear permite ejecutar la Regularización Lasso en modelos de Regresión Logística. Para Ridge se usa lbfgs.

- **Max Iter**. Como su nombre indica, se podría considerar como el Stop Iteration del modelo.
"""

def evaluate_model(YTest, predictions, score):
  """
  Evalúa el rendimiento del modelo utilizando métricas como la precisión, el informe de clasificación y la matriz de confusión.

  Parámetros:
  - YTest: Valores reales del conjunto de prueba.
  - predictions: Valores predichos por el modelo.
  - score: Puntuación del modelo.
  """

  # Calcular y mostrar la precisión del modelo
  print("\n\tAccuracy: ", accuracy_score(YTest, predictions))
  print("\n\tLa precisión del modelo es de {}%".format(score))

  # Calcular y mostrar el informe de clasificación
  result = classification_report(YTest, predictions, zero_division=0)
  print('\n\tInforme de clasificación\n')
  print(result)

  # Calcular y mostrar la matriz de confusión
  print("\n\tMatriz de confusión\n")
  print(confusion_matrix(YTest, predictions))

"""#### <font color='blue'>7)  Selección de la mejor hipótesis para el problema. Discuta el enfoque seguido y el criterio de selección usado. ¿Cúal es su error $E_{out}$? 1 punto.

Una vez se tiene todo el conjunto de datos preprocesado falta aplicar el modelo de Regresión Logística para aprender la función de predecir cuándo la compañía de seguros debe dar un seguro de caravana a un cliente.

Para esto, se importa la función LogisticRegression() de la librería sklearn y se configuran sus parámetros. En primer lugar se va a ejecutar el modelo de Regresión Logística junto con la Regularización Ridge.
"""

# REGRESIÓN LOGÍSTICA + RIDGE - Sin balanceado

penalty = "l2"  # Tipo de penalización (l1, l2, elasticnet, none)
solver = "lbfgs"  # Algoritmo solver utilizado para la optimización (lbfgs, saga, newton-cg, liblinear)
max_iter = 1500  # Número máximo de iteraciones para la convergencia del modelo
class_weight = None  # Peso asignado a las clases (None para igual peso)

# Crear una instancia del modelo de Regresión Logística con los parámetros especificados
logm = LogisticRegression(penalty=penalty, solver=solver, max_iter=max_iter, class_weight=class_weight)

# Ajustar el modelo utilizando los datos de entrenamiento preprocesados
model = logm.fit(X_train_prep, Y_train_prep)

# Realizar predicciones en los datos de prueba preprocesados
predictions = model.predict(X_test_prep)

# Calcular el score de precisión del modelo
score_logreg = round(logm.score(X_test_prep, Y_test_outlrs) * 100, 2)

# Imprimir la forma de los datos de prueba preprocesados
print(X_test_prep.shape)

# Evaluar el modelo utilizando diferentes métricas
evaluate_model(Y_test_prep, predictions, score_logreg)

"""Y efectivamente, aquí ocurre lo mencionado antes cuando se tiene un conjunto de datos desbalanceado. La precisión del modelo es de un 94% casi, sin embargo, el modelo no es capaz de reconocer a la clase 1 con un 0% de forma individual, siendo además todos los elementos falsos negativos. A simple vista puede parecer un resultado gratificante, sin embargo la realidad es muy distinta.

Debido a esta situación se intenta aplicar un balanceo de datos. Esta técnica no es especialmente recomendada, ya que para realizar esto no queda más remedio que hacer dos cosas:

1. **Supresión de Datos.** Esto es básicamente lo que se hizo en el problema de Regresión. Es cierto que mejoró el error notoriamente pero, un gran precio a pagar es el de eliminar datos que sean esenciales a la hora de aprender un modelo.
2. **Creación de Datos en la clase minoritaria.** Esta segunda opción podría parecer coherente, sin embargo, existe la posibilidad de generar un overfitting desmesurado.

La opción que se ha barajado después de ver qué posibilidades era mejor ha sido aplicar la Regresión Logística ajustando un parámetro más, el class weight. Este parámetro lo que haces es nivelar de una forma no muy abrupta la clase más minoritaria de forma que pueda intentarse así conseguir una mayor representatividad.
"""

# REGRESIÓN LOGÍSTICA + RIDGE - Balanceando las clases minoritarias con Class_Weight Balanced

penalty = "l2"  # Tipo de penalización (l1, l2, elasticnet, none)
solver = "lbfgs"  # Algoritmo solver utilizado para la optimización (lbfgs, saga, newton-cg, liblinear)
class_weight = "balanced"  # Peso asignado a las clases (balanced para equilibrar las clases)

# Crear una instancia del modelo de Regresión Logística con balanceo de clases y los parámetros especificados
logm_balanced = LogisticRegression(penalty=penalty, solver=solver, max_iter=1500, class_weight=class_weight)

# Ajustar el modelo utilizando los datos de entrenamiento preprocesados con clases balanceadas
model = logm_balanced.fit(X_train_prep, Y_train_outlrs)

# Realizar predicciones en los datos de prueba preprocesados
predictions = model.predict(X_test_prep)

# Calcular el score de precisión del modelo
score_logreg = round(logm_balanced.score(X_test_prep, Y_test_outlrs) * 100, 2)

# Imprimir la forma de los datos de prueba preprocesados
print(X_test_prep.shape)

# Evaluar el modelo utilizando diferentes métricas
evaluate_model(Y_test_outlrs, predictions, score_logreg)

# Imprimir un comentario adicional sobre el balanceo de clases
print("\nIntentando balancear la clase minoritaria ha conseguido que haya un mayor número de falsos positivos\n\tpara la clase 0 aunque ahora la clase 1 está mejor representada")

"""Se ha perdido cerca de un 30 % de precisión con el modelo ajustado, sin embargo, ¿es realmente una pérdida? Es cierto que ahora hay más falsos positivos que antes, sin embargo la precisión de la clase 0 sigue siendo realmente prometedora, mientras que ahora la clase 1 ha aumentado su poder
clasificatorio individual. El número de falsos negativos ha disminuido considerablemente ajustándose mejor ambas representaciones de las clases. Parece ser que ha sido una buena opción el intentar balancear la clase minoritaria, aunque haya supuesto obtener más falsos positivos. Sin embargo,
no es que haya empeorado la clase 0 como tal. Como se ha comentado siempre en clase, hay que intentar buscar un promedio entre lo malo y lo bueno.

Por último, para finalizar la Regresión Logística, se ha aplicado el mismo procedimiento pero esta vez haciendo uso de la Regularización Lasso. Sin embargo, no ha habido cambio ninguno respecto a la anterior ejecución.
"""

# REGRESIÓN LOGÍSTICA + LASSO - Balanceando las clases minoritarias con Class_Weight Balanced
penalty = "l2"  # Tipo de penalización (l1, l2, elasticnet, none)
solver = "liblinear"  # Algoritmo solver utilizado para la optimización (liblinear, saga)
class_weight = "balanced"  # Peso asignado a las clases (balanced para equilibrar las clases)

# Crear una instancia del modelo de Regresión Logística con balanceo de clases y los parámetros especificados
logm_balanced = LogisticRegression(penalty=penalty, solver=solver, max_iter=1500, class_weight=class_weight)

# Ajustar el modelo utilizando los datos de entrenamiento preprocesados con clases balanceadas
model = logm_balanced.fit(X_train_prep, Y_train_prep)

# Realizar predicciones en los datos de prueba preprocesados
predictions = model.predict(X_test_prep)

# Calcular el score de precisión del modelo
score_logreg = round(logm_balanced.score(X_test_prep, Y_test_prep) * 100, 2)

# Imprimir la forma de los datos de prueba preprocesados
print(X_test_prep.shape)

# Evaluar el modelo utilizando diferentes métricas
evaluate_model(Y_test_prep, predictions, score_logreg)

# Imprimir un comentario adicional sobre el balanceo de clases
print("\nIntentando balancear la clase minoritaria ha conseguido que haya un mayor número de falsos positivos\n\tpara la clase 0 aunque ahora la clase 1 está mejor representada")

"""Si probamos con cross validation observamos que los resultados obtenidos son casi idénticos"""

# REGRESIÓN LOGÍSTICA + RIDGE + CV - Balanceando las clases minoritarias con Class_Weight Balanced

penalty = "l2"  # Tipo de penalización (l1, l2, elasticnet, none)
solver = "lbfgs"  # Algoritmo solver utilizado para la optimización (lbfgs, saga, ...)
class_weight = "balanced"  # Peso asignado a las clases (balanced para equilibrar las clases)

# Crear una instancia del modelo de Regresión Logística con balanceo de clases y los parámetros especificados
logm_balanced = LogisticRegression(penalty=penalty, solver=solver, max_iter=1500, class_weight=class_weight)

# Ajustar el modelo utilizando los datos de entrenamiento preprocesados con clases balanceadas
model = logm_balanced.fit(X_train_prep, Y_train_prep)

# Realizar la validación cruzada en el modelo de regresión logística
pred = cross_val_predict(model, X_test_prep, Y_test_prep, cv=5)

# Calcular el score de precisión del modelo en los datos de prueba
score_logreg = round(logm_balanced.score(X_test_prep, Y_test_prep) * 100, 2)

# Imprimir la forma de los datos de prueba preprocesados
print(X_test_prep.shape)

# Evaluar el modelo utilizando diferentes métricas
evaluate_model(Y_test_prep, pred, score_logreg)

# Imprimir un comentario adicional sobre el balanceo de clases
print("\nIntentando balancear la clase minoritaria ha conseguido que haya un mayor número de falsos positivos\n\tpara la clase 0 aunque ahora la clase 1 está mejor representada")

# REGRESIÓN LOGÍSTICA + LASSO + CV - Balanceando las clases minoritarias con Class_Weight Balanced

penalty = "l2"  # Tipo de penalización (l1, l2, elasticnet, none)
solver = "liblinear"  # Algoritmo solver utilizado para la optimización (liblinear, saga, ...)
class_weight = "balanced"  # Peso asignado a las clases (balanced para equilibrar las clases)

# Crear una instancia del modelo de Regresión Logística con balanceo de clases y los parámetros especificados
logm_balanced = LogisticRegression(penalty=penalty, solver=solver, max_iter=1500, class_weight=class_weight)

# Ajustar el modelo utilizando los datos de entrenamiento preprocesados con clases balanceadas
model = logm_balanced.fit(X_train_prep, Y_train_prep)

# Realizar la validación cruzada en el modelo de regresión logística
pred = cross_val_predict(model, X_test_prep, Y_test_prep, cv=5)

# Calcular el score de precisión del modelo en los datos de prueba
score_logreg = round(logm_balanced.score(X_test_prep, Y_test_prep) * 100, 2)

# Imprimir la forma de los datos de prueba preprocesados
print(X_test_prep.shape)

# Evaluar el modelo utilizando diferentes métricas
evaluate_model(Y_test_prep, pred, score_logreg)

# Imprimir un comentario adicional sobre el balanceo de clases
print("\nIntentando balancear la clase minoritaria ha conseguido que haya un mayor número de falsos positivos\n\tpara la clase 0 aunque ahora la clase 1 está mejor representada")

"""#### <font color='blue'>8)  Construya las curvas de aprendizaje del modelo, y discuta la calidad del ajuste obtenido a la vista de la conducta de dichas curvas. 0.5 puntos.

Apreciando simplemente las Curvas de Aprendizaje, en este caso no sería posible determinar con certeza que de verdad es mejor aquel modelo donde solo se aplica Ridge junto a la Regresión Logística. Es cierto que tiene un mayor porcentaje de precisión, sin embargo, la pregunta es, ¿está dispuesto a perder esa representación de una clase en un problema de Clasificación Binaria?

No obstante, se puede asegurar que no existe Overfitting ya que las curvas coinciden. Comienza no estando bien ajustado, hasta que termina de ajustarse, aunque no de una forma perfecta, ya que existe el error aunque bastante bajo. Aun así, como se ha mencionado, hay que seguir teniendo en cuenta los falsos positivos obtenidos y los falsos negativos, así como lo poco representativa que es una clase en Regresión Logística.
"""

def show_learningCurve(X_train, Y_train, model_, titulo, scr_ = "accuracy", cv_ = 10, trn_size_ = np.linspace(0.01, 1.0, 50)):
  """
  Muestra la curva de aprendizaje del modelo utilizando diferentes tamaños de conjunto de entrenamiento.

  Parámetros:
  - XTrain: Características del conjunto de entrenamiento.
  - YTrain: Objetivo del conjunto de entrenamiento.
  - model_: Modelo de aprendizaje a evaluar.
  - titulo: Título del gráfico.
  - cv_: Número de subdivisiones en la estrategia de validación cruzada.
  - scr_: Métrica de evaluación utilizada.
  - trn_size_: Tamaños del conjunto de entrenamiento para los que se calcula el puntaje.
  """
  # Se calcula la curva de aprendizaje
  sizes, training_scores, testing_scores = learning_curve(model_, X_train, Y_train, cv=cv_, scoring=scr_, train_sizes=trn_size_)

  # Cálculo de la media de los puntajes de entrenamiento y validación cruzada
  mean_training = np.mean(training_scores, axis=1)
  mean_testing = np.mean(testing_scores, axis=1)

  # Graficar la curva de aprendizaje
  plt.plot(sizes, mean_training, '--', color="b", label="Training score")
  plt.plot(sizes, mean_testing, color="g", label="Cross-validation score")

  plt.title(titulo)
  plt.xlabel("Training Set Size")
  plt.ylabel(scr_)
  plt.legend(loc="best")
  plt.tight_layout()
  plt.show()

show_learningCurve(X_train_prep, Y_train_prep, logm_balanced, "LEARNING CURVE - Regresión Logística + Ridge (Accuracy)")
show_learningCurve(X_train_prep, Y_train_prep, logm_balanced, "LEARNING CURVE - Regresión Logística + Ridge (Precision)", scr_='precision')
show_learningCurve(X_train_prep, Y_train_prep, logm_balanced, "LEARNING CURVE - Regresión Logística + Ridge (F1-score)", scr_='f1')

"""#### <font color='blue'>9)  Suponga ahora que Ud. debe realizar este ajuste para una empresa que le ha proporcionado los datos, sin distinción entre training y test. ¿Cúal sería el mejor modelo que les propondría, y qué error  $E_{out}$ les diría que tiene? Justifique todas las decisiones. 0.5 puntos.

El proceso que seguiría para contemplar la validez de los datos, así como el trato a los mismos para su uso sería el que se ha ido comentando durante el desarrollo de los puntos anteriores. El paso más importante es eliminar aquellos datos que no aporten nada, bien por su nulo valor en las
características, o bien por su baja varianza.

En este caso, cuando ocurre que hay valores categóricos, es importante transformarlos a valores numéricos con los que se pueda estudiar un comportamiento y se pueda realizar siempre un análisis competente.

Tal y como se ha mencionado, en el caso de problemas de clasificación no debería bastar solo y conformarse con valorar la precisión del modelo en su totalidad, pues puede ocurrir el caso de que se estén despreciando algunas clases. En este caso, sin ir más lejos, la precisión es de un 93%
tras aplicar simplemente la Regresión Logística, sin embargo la representación de la clase 1 era nula. Suponiéndose en este caso en cuestión sería como tener que decidir entre aquel que ya es un cliente y un potencial cliente. ¿Hay acaso alguna de las opciones que tenga menos peso? Un cliente, por serlo no es menos importante, es al final una fuente de ingreso para la empresa mientras lo sea,
pero, ¿y el que no es cliente? Sigue siendo igual de importante, ya que lo que es necesario estudiar es como atraer a ese posible futuro cliente.

A modo de conclusión y opinión personal, el modelo que mejor clasifica los datos es aquel en el que se aplica Ridge con un Balanceo de Datos (o Lasso con ese balanceo de datos, ya que no mejora ni empeora) ya que se consigue una representación equitativa de ambas clases en mayor medida.

A costa de sacrificar un número de falsos positivos, se obtienen verdaderos negativos en mayor cantidad, que, a mi juicio es mucho más importante tratándose de la clase minoritaria. Poniendo en un punto opuesto, ¿qué sentido tendría tener un modelo cuya precisión sea del 90 % o más y no fuese capaz de representar a las clases minoritarias? Aun así, como afirmación final, pese a los datos tan desbalanceados que se han proporcionado, un valor del modelo del 80% aproximadamente, me parece bastante aceptable.
"""